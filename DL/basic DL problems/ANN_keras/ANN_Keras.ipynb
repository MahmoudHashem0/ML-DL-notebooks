{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "frequency = 2500  # Set Frequency To 2500 Hertz\n",
    "duration = 1000  # Set Duration To 1000 ms == 1 second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fmnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "x_val, x_train = x_train[:5000], x_train[5000:]\n",
    "y_val, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "\"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = (28,28), name=\"Input_layer\")) # input layer\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\", name=\"hidden_layer_1\")) # hidden layer\n",
    "model.add(keras.layers.Dense(200, activation=\"relu\", name=\"hidden_layer_2\")) # hidden layer\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\", name=\"hidden_layer_3\")) # hidden layer\n",
    "model.add(keras.layers.Dense(50, activation=\"relu\", name=\"hidden_layer_4\")) # hidden layer\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\", name=\"output_layer\")) # output layer\n",
    "model._name = 'fmnist_dataset_classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = keras.callbacks.EarlyStopping(restore_best_weights=True, patience=100, monitor=\"val_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "55000/5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2698 - accuracy: 0.9014 - val_loss: 0.3120 - val_accuracy: 0.8882\n",
      "Epoch 2/2000\n",
      "1/1 [==============================] - 1s 546ms/step - loss: 0.2646 - accuracy: 0.9034 - val_loss: 0.3091 - val_accuracy: 0.8866\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.2624 - accuracy: 0.9046 - val_loss: 0.3090 - val_accuracy: 0.8876\n",
      "Epoch 4/2000\n",
      "1/1 [==============================] - 1s 565ms/step - loss: 0.2621 - accuracy: 0.9045 - val_loss: 0.3088 - val_accuracy: 0.8870\n",
      "Epoch 5/2000\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.2619 - accuracy: 0.9046 - val_loss: 0.3088 - val_accuracy: 0.8870\n",
      "Epoch 6/2000\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 0.2618 - accuracy: 0.9047 - val_loss: 0.3088 - val_accuracy: 0.8868\n",
      "Epoch 7/2000\n",
      "1/1 [==============================] - 1s 592ms/step - loss: 0.2617 - accuracy: 0.9048 - val_loss: 0.3087 - val_accuracy: 0.8866\n",
      "Epoch 8/2000\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 0.2616 - accuracy: 0.9048 - val_loss: 0.3087 - val_accuracy: 0.8868\n",
      "Epoch 9/2000\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.2615 - accuracy: 0.9048 - val_loss: 0.3087 - val_accuracy: 0.8870\n",
      "Epoch 10/2000\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 0.2614 - accuracy: 0.9048 - val_loss: 0.3086 - val_accuracy: 0.8866\n",
      "Epoch 11/2000\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 0.2613 - accuracy: 0.9049 - val_loss: 0.3086 - val_accuracy: 0.8866\n",
      "Epoch 12/2000\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.2613 - accuracy: 0.9050 - val_loss: 0.3086 - val_accuracy: 0.8866\n",
      "Epoch 13/2000\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 0.2612 - accuracy: 0.9050 - val_loss: 0.3086 - val_accuracy: 0.8866\n",
      "Epoch 14/2000\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.2611 - accuracy: 0.9050 - val_loss: 0.3086 - val_accuracy: 0.8868\n",
      "Epoch 15/2000\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.2611 - accuracy: 0.9051 - val_loss: 0.3085 - val_accuracy: 0.8868\n",
      "Epoch 16/2000\n",
      "1/1 [==============================] - 1s 530ms/step - loss: 0.2610 - accuracy: 0.9051 - val_loss: 0.3085 - val_accuracy: 0.8868\n",
      "Epoch 17/2000\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.2609 - accuracy: 0.9051 - val_loss: 0.3085 - val_accuracy: 0.8866\n",
      "Epoch 18/2000\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.2609 - accuracy: 0.9051 - val_loss: 0.3085 - val_accuracy: 0.8868\n",
      "Epoch 19/2000\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.2608 - accuracy: 0.9050 - val_loss: 0.3084 - val_accuracy: 0.8868\n",
      "Epoch 20/2000\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 0.2607 - accuracy: 0.9050 - val_loss: 0.3084 - val_accuracy: 0.8868\n",
      "Epoch 21/2000\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.2607 - accuracy: 0.9051 - val_loss: 0.3084 - val_accuracy: 0.8868\n",
      "Epoch 22/2000\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 0.2606 - accuracy: 0.9051 - val_loss: 0.3084 - val_accuracy: 0.8868\n",
      "Epoch 23/2000\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 0.2606 - accuracy: 0.9050 - val_loss: 0.3084 - val_accuracy: 0.8868\n",
      "Epoch 24/2000\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.2605 - accuracy: 0.9050 - val_loss: 0.3083 - val_accuracy: 0.8868\n",
      "Epoch 25/2000\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.2605 - accuracy: 0.9050 - val_loss: 0.3083 - val_accuracy: 0.8868\n",
      "Epoch 26/2000\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 0.2604 - accuracy: 0.9050 - val_loss: 0.3083 - val_accuracy: 0.8868\n",
      "Epoch 27/2000\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.2603 - accuracy: 0.9051 - val_loss: 0.3083 - val_accuracy: 0.8866\n",
      "Epoch 28/2000\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 0.2603 - accuracy: 0.9051 - val_loss: 0.3083 - val_accuracy: 0.8866\n",
      "Epoch 29/2000\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 0.2602 - accuracy: 0.9052 - val_loss: 0.3082 - val_accuracy: 0.8866\n",
      "Epoch 30/2000\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.2602 - accuracy: 0.9053 - val_loss: 0.3082 - val_accuracy: 0.8868\n",
      "Epoch 31/2000\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.2601 - accuracy: 0.9052 - val_loss: 0.3082 - val_accuracy: 0.8868\n",
      "Epoch 32/2000\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 0.2601 - accuracy: 0.9053 - val_loss: 0.3082 - val_accuracy: 0.8870\n",
      "Epoch 33/2000\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 0.2600 - accuracy: 0.9053 - val_loss: 0.3082 - val_accuracy: 0.8870\n",
      "Epoch 34/2000\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.2599 - accuracy: 0.9054 - val_loss: 0.3081 - val_accuracy: 0.8872\n",
      "Epoch 35/2000\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.2599 - accuracy: 0.9054 - val_loss: 0.3081 - val_accuracy: 0.8872\n",
      "Epoch 36/2000\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.2598 - accuracy: 0.9055 - val_loss: 0.3081 - val_accuracy: 0.8872\n",
      "Epoch 37/2000\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.2598 - accuracy: 0.9055 - val_loss: 0.3081 - val_accuracy: 0.8872\n",
      "Epoch 38/2000\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.2597 - accuracy: 0.9055 - val_loss: 0.3081 - val_accuracy: 0.8872\n",
      "Epoch 39/2000\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 0.2597 - accuracy: 0.9055 - val_loss: 0.3081 - val_accuracy: 0.8872\n",
      "Epoch 40/2000\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.2596 - accuracy: 0.9056 - val_loss: 0.3080 - val_accuracy: 0.8872\n",
      "Epoch 41/2000\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.2596 - accuracy: 0.9056 - val_loss: 0.3080 - val_accuracy: 0.8872\n",
      "Epoch 42/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2595 - accuracy: 0.9056 - val_loss: 0.3080 - val_accuracy: 0.8874\n",
      "Epoch 43/2000\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.2594 - accuracy: 0.9056 - val_loss: 0.3080 - val_accuracy: 0.8876\n",
      "Epoch 44/2000\n",
      "1/1 [==============================] - 1s 716ms/step - loss: 0.2594 - accuracy: 0.9056 - val_loss: 0.3080 - val_accuracy: 0.8876\n",
      "Epoch 45/2000\n",
      "1/1 [==============================] - 1s 734ms/step - loss: 0.2593 - accuracy: 0.9057 - val_loss: 0.3079 - val_accuracy: 0.8878\n",
      "Epoch 46/2000\n",
      "1/1 [==============================] - 1s 697ms/step - loss: 0.2593 - accuracy: 0.9057 - val_loss: 0.3079 - val_accuracy: 0.8878\n",
      "Epoch 47/2000\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.2592 - accuracy: 0.9057 - val_loss: 0.3079 - val_accuracy: 0.8878\n",
      "Epoch 48/2000\n",
      "1/1 [==============================] - 1s 714ms/step - loss: 0.2592 - accuracy: 0.9058 - val_loss: 0.3079 - val_accuracy: 0.8878\n",
      "Epoch 49/2000\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.2591 - accuracy: 0.9058 - val_loss: 0.3079 - val_accuracy: 0.8878\n",
      "Epoch 50/2000\n",
      "1/1 [==============================] - 1s 692ms/step - loss: 0.2591 - accuracy: 0.9058 - val_loss: 0.3078 - val_accuracy: 0.8876\n",
      "Epoch 51/2000\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.2590 - accuracy: 0.9059 - val_loss: 0.3078 - val_accuracy: 0.8876\n",
      "Epoch 52/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2590 - accuracy: 0.9059 - val_loss: 0.3078 - val_accuracy: 0.8876\n",
      "Epoch 53/2000\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 0.2589 - accuracy: 0.9059 - val_loss: 0.3078 - val_accuracy: 0.8876\n",
      "Epoch 54/2000\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 0.2589 - accuracy: 0.9059 - val_loss: 0.3078 - val_accuracy: 0.8876\n",
      "Epoch 55/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2588 - accuracy: 0.9059 - val_loss: 0.3078 - val_accuracy: 0.8878\n",
      "Epoch 56/2000\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 0.2587 - accuracy: 0.9060 - val_loss: 0.3077 - val_accuracy: 0.8876\n",
      "Epoch 57/2000\n",
      "1/1 [==============================] - 1s 686ms/step - loss: 0.2587 - accuracy: 0.9059 - val_loss: 0.3077 - val_accuracy: 0.8880\n",
      "Epoch 58/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 681ms/step - loss: 0.2586 - accuracy: 0.9060 - val_loss: 0.3077 - val_accuracy: 0.8878\n",
      "Epoch 59/2000\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.2586 - accuracy: 0.9060 - val_loss: 0.3077 - val_accuracy: 0.8882\n",
      "Epoch 60/2000\n",
      "1/1 [==============================] - 1s 686ms/step - loss: 0.2585 - accuracy: 0.9061 - val_loss: 0.3077 - val_accuracy: 0.8878\n",
      "Epoch 61/2000\n",
      "1/1 [==============================] - 1s 685ms/step - loss: 0.2585 - accuracy: 0.9060 - val_loss: 0.3077 - val_accuracy: 0.8882\n",
      "Epoch 62/2000\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 0.2584 - accuracy: 0.9060 - val_loss: 0.3076 - val_accuracy: 0.8878\n",
      "Epoch 63/2000\n",
      "1/1 [==============================] - 1s 673ms/step - loss: 0.2584 - accuracy: 0.9061 - val_loss: 0.3076 - val_accuracy: 0.8882\n",
      "Epoch 64/2000\n",
      "1/1 [==============================] - 1s 696ms/step - loss: 0.2583 - accuracy: 0.9060 - val_loss: 0.3076 - val_accuracy: 0.8878\n",
      "Epoch 65/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2583 - accuracy: 0.9061 - val_loss: 0.3076 - val_accuracy: 0.8882\n",
      "Epoch 66/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2582 - accuracy: 0.9060 - val_loss: 0.3076 - val_accuracy: 0.8880\n",
      "Epoch 67/2000\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.2582 - accuracy: 0.9062 - val_loss: 0.3076 - val_accuracy: 0.8882\n",
      "Epoch 68/2000\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 0.2581 - accuracy: 0.9061 - val_loss: 0.3075 - val_accuracy: 0.8880\n",
      "Epoch 69/2000\n",
      "1/1 [==============================] - 1s 696ms/step - loss: 0.2581 - accuracy: 0.9063 - val_loss: 0.3075 - val_accuracy: 0.8884\n",
      "Epoch 70/2000\n",
      "1/1 [==============================] - 1s 719ms/step - loss: 0.2580 - accuracy: 0.9062 - val_loss: 0.3075 - val_accuracy: 0.8882\n",
      "Epoch 71/2000\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.2580 - accuracy: 0.9063 - val_loss: 0.3075 - val_accuracy: 0.8884\n",
      "Epoch 72/2000\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.2579 - accuracy: 0.9063 - val_loss: 0.3075 - val_accuracy: 0.8882\n",
      "Epoch 73/2000\n",
      "1/1 [==============================] - 1s 685ms/step - loss: 0.2579 - accuracy: 0.9064 - val_loss: 0.3075 - val_accuracy: 0.8884\n",
      "Epoch 74/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2578 - accuracy: 0.9063 - val_loss: 0.3074 - val_accuracy: 0.8882\n",
      "Epoch 75/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2577 - accuracy: 0.9064 - val_loss: 0.3074 - val_accuracy: 0.8884\n",
      "Epoch 76/2000\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.2577 - accuracy: 0.9064 - val_loss: 0.3074 - val_accuracy: 0.8882\n",
      "Epoch 77/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2576 - accuracy: 0.9065 - val_loss: 0.3074 - val_accuracy: 0.8884\n",
      "Epoch 78/2000\n",
      "1/1 [==============================] - 1s 679ms/step - loss: 0.2576 - accuracy: 0.9064 - val_loss: 0.3074 - val_accuracy: 0.8884\n",
      "Epoch 79/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2575 - accuracy: 0.9066 - val_loss: 0.3074 - val_accuracy: 0.8880\n",
      "Epoch 80/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2575 - accuracy: 0.9065 - val_loss: 0.3073 - val_accuracy: 0.8884\n",
      "Epoch 81/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2574 - accuracy: 0.9066 - val_loss: 0.3073 - val_accuracy: 0.8882\n",
      "Epoch 82/2000\n",
      "1/1 [==============================] - 1s 704ms/step - loss: 0.2574 - accuracy: 0.9065 - val_loss: 0.3073 - val_accuracy: 0.8882\n",
      "Epoch 83/2000\n",
      "1/1 [==============================] - 1s 690ms/step - loss: 0.2573 - accuracy: 0.9066 - val_loss: 0.3073 - val_accuracy: 0.8882\n",
      "Epoch 84/2000\n",
      "1/1 [==============================] - 1s 672ms/step - loss: 0.2573 - accuracy: 0.9065 - val_loss: 0.3073 - val_accuracy: 0.8882\n",
      "Epoch 85/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2572 - accuracy: 0.9067 - val_loss: 0.3072 - val_accuracy: 0.8884\n",
      "Epoch 86/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2572 - accuracy: 0.9065 - val_loss: 0.3072 - val_accuracy: 0.8882\n",
      "Epoch 87/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2571 - accuracy: 0.9067 - val_loss: 0.3072 - val_accuracy: 0.8886\n",
      "Epoch 88/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2571 - accuracy: 0.9066 - val_loss: 0.3072 - val_accuracy: 0.8882\n",
      "Epoch 89/2000\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 0.2570 - accuracy: 0.9067 - val_loss: 0.3072 - val_accuracy: 0.8886\n",
      "Epoch 90/2000\n",
      "1/1 [==============================] - 1s 679ms/step - loss: 0.2570 - accuracy: 0.9066 - val_loss: 0.3072 - val_accuracy: 0.8882\n",
      "Epoch 91/2000\n",
      "1/1 [==============================] - 1s 680ms/step - loss: 0.2569 - accuracy: 0.9068 - val_loss: 0.3071 - val_accuracy: 0.8886\n",
      "Epoch 92/2000\n",
      "1/1 [==============================] - 1s 668ms/step - loss: 0.2569 - accuracy: 0.9067 - val_loss: 0.3071 - val_accuracy: 0.8882\n",
      "Epoch 93/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2568 - accuracy: 0.9067 - val_loss: 0.3071 - val_accuracy: 0.8890\n",
      "Epoch 94/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2568 - accuracy: 0.9067 - val_loss: 0.3071 - val_accuracy: 0.8882\n",
      "Epoch 95/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2567 - accuracy: 0.9068 - val_loss: 0.3071 - val_accuracy: 0.8888\n",
      "Epoch 96/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2567 - accuracy: 0.9067 - val_loss: 0.3071 - val_accuracy: 0.8882\n",
      "Epoch 97/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2566 - accuracy: 0.9069 - val_loss: 0.3070 - val_accuracy: 0.8886\n",
      "Epoch 98/2000\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 0.2566 - accuracy: 0.9068 - val_loss: 0.3071 - val_accuracy: 0.8884\n",
      "Epoch 99/2000\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.2565 - accuracy: 0.9069 - val_loss: 0.3070 - val_accuracy: 0.8886\n",
      "Epoch 100/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2565 - accuracy: 0.9068 - val_loss: 0.3070 - val_accuracy: 0.8884\n",
      "Epoch 101/2000\n",
      "1/1 [==============================] - 1s 686ms/step - loss: 0.2564 - accuracy: 0.9070 - val_loss: 0.3070 - val_accuracy: 0.8886\n",
      "Epoch 102/2000\n",
      "1/1 [==============================] - 1s 713ms/step - loss: 0.2564 - accuracy: 0.9068 - val_loss: 0.3070 - val_accuracy: 0.8884\n",
      "Epoch 103/2000\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 0.2563 - accuracy: 0.9071 - val_loss: 0.3069 - val_accuracy: 0.8888\n",
      "Epoch 104/2000\n",
      "1/1 [==============================] - 1s 685ms/step - loss: 0.2563 - accuracy: 0.9069 - val_loss: 0.3070 - val_accuracy: 0.8884\n",
      "Epoch 105/2000\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 0.2562 - accuracy: 0.9071 - val_loss: 0.3069 - val_accuracy: 0.8888\n",
      "Epoch 106/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2562 - accuracy: 0.9069 - val_loss: 0.3069 - val_accuracy: 0.8884\n",
      "Epoch 107/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2561 - accuracy: 0.9071 - val_loss: 0.3069 - val_accuracy: 0.8888\n",
      "Epoch 108/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2561 - accuracy: 0.9070 - val_loss: 0.3069 - val_accuracy: 0.8886\n",
      "Epoch 109/2000\n",
      "1/1 [==============================] - 1s 667ms/step - loss: 0.2561 - accuracy: 0.9072 - val_loss: 0.3069 - val_accuracy: 0.8890\n",
      "Epoch 110/2000\n",
      "1/1 [==============================] - 1s 667ms/step - loss: 0.2560 - accuracy: 0.9071 - val_loss: 0.3069 - val_accuracy: 0.8886\n",
      "Epoch 111/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2560 - accuracy: 0.9072 - val_loss: 0.3068 - val_accuracy: 0.8890\n",
      "Epoch 112/2000\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 0.2559 - accuracy: 0.9072 - val_loss: 0.3069 - val_accuracy: 0.8886\n",
      "Epoch 113/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2559 - accuracy: 0.9073 - val_loss: 0.3068 - val_accuracy: 0.8890\n",
      "Epoch 114/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2558 - accuracy: 0.9072 - val_loss: 0.3068 - val_accuracy: 0.8888\n",
      "Epoch 115/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2558 - accuracy: 0.9073 - val_loss: 0.3068 - val_accuracy: 0.8892\n",
      "Epoch 116/2000\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 0.2557 - accuracy: 0.9071 - val_loss: 0.3068 - val_accuracy: 0.8886\n",
      "Epoch 117/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2557 - accuracy: 0.9074 - val_loss: 0.3068 - val_accuracy: 0.8894\n",
      "Epoch 118/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2556 - accuracy: 0.9071 - val_loss: 0.3068 - val_accuracy: 0.8888\n",
      "Epoch 119/2000\n",
      "1/1 [==============================] - 1s 671ms/step - loss: 0.2556 - accuracy: 0.9074 - val_loss: 0.3068 - val_accuracy: 0.8892\n",
      "Epoch 120/2000\n",
      "1/1 [==============================] - 1s 693ms/step - loss: 0.2555 - accuracy: 0.9071 - val_loss: 0.3068 - val_accuracy: 0.8888\n",
      "Epoch 121/2000\n",
      "1/1 [==============================] - 1s 712ms/step - loss: 0.2555 - accuracy: 0.9074 - val_loss: 0.3067 - val_accuracy: 0.8894\n",
      "Epoch 122/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2555 - accuracy: 0.9072 - val_loss: 0.3067 - val_accuracy: 0.8888\n",
      "Epoch 123/2000\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.2554 - accuracy: 0.9073 - val_loss: 0.3067 - val_accuracy: 0.8892\n",
      "Epoch 124/2000\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 0.2554 - accuracy: 0.9072 - val_loss: 0.3067 - val_accuracy: 0.8890\n",
      "Epoch 125/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2553 - accuracy: 0.9074 - val_loss: 0.3067 - val_accuracy: 0.8890\n",
      "Epoch 126/2000\n",
      "1/1 [==============================] - 1s 669ms/step - loss: 0.2553 - accuracy: 0.9073 - val_loss: 0.3067 - val_accuracy: 0.8890\n",
      "Epoch 127/2000\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 0.2553 - accuracy: 0.9073 - val_loss: 0.3067 - val_accuracy: 0.8894\n",
      "Epoch 128/2000\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 0.2552 - accuracy: 0.9073 - val_loss: 0.3067 - val_accuracy: 0.8892\n",
      "Epoch 129/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2552 - accuracy: 0.9072 - val_loss: 0.3067 - val_accuracy: 0.8894\n",
      "Epoch 130/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2552 - accuracy: 0.9073 - val_loss: 0.3067 - val_accuracy: 0.8892\n",
      "Epoch 131/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2551 - accuracy: 0.9071 - val_loss: 0.3067 - val_accuracy: 0.8890\n",
      "Epoch 132/2000\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 0.2551 - accuracy: 0.9074 - val_loss: 0.3067 - val_accuracy: 0.8892\n",
      "Epoch 133/2000\n",
      "1/1 [==============================] - 1s 691ms/step - loss: 0.2551 - accuracy: 0.9071 - val_loss: 0.3067 - val_accuracy: 0.8888\n",
      "Epoch 134/2000\n",
      "1/1 [==============================] - 1s 676ms/step - loss: 0.2550 - accuracy: 0.9075 - val_loss: 0.3067 - val_accuracy: 0.8894\n",
      "Epoch 135/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2550 - accuracy: 0.9072 - val_loss: 0.3067 - val_accuracy: 0.8896\n",
      "Epoch 136/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2550 - accuracy: 0.9076 - val_loss: 0.3067 - val_accuracy: 0.8890\n",
      "Epoch 137/2000\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 0.2549 - accuracy: 0.9072 - val_loss: 0.3067 - val_accuracy: 0.8898\n",
      "Epoch 138/2000\n",
      "1/1 [==============================] - 1s 685ms/step - loss: 0.2549 - accuracy: 0.9076 - val_loss: 0.3067 - val_accuracy: 0.8888\n",
      "Epoch 139/2000\n",
      "1/1 [==============================] - 1s 689ms/step - loss: 0.2549 - accuracy: 0.9074 - val_loss: 0.3067 - val_accuracy: 0.8896\n",
      "Epoch 140/2000\n",
      "1/1 [==============================] - 1s 686ms/step - loss: 0.2549 - accuracy: 0.9074 - val_loss: 0.3068 - val_accuracy: 0.8888\n",
      "Epoch 141/2000\n",
      "1/1 [==============================] - 1s 667ms/step - loss: 0.2549 - accuracy: 0.9074 - val_loss: 0.3067 - val_accuracy: 0.8894\n",
      "Epoch 142/2000\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 0.2548 - accuracy: 0.9074 - val_loss: 0.3068 - val_accuracy: 0.8886\n",
      "Epoch 143/2000\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 0.2548 - accuracy: 0.9073 - val_loss: 0.3068 - val_accuracy: 0.8892\n",
      "Epoch 144/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2548 - accuracy: 0.9075 - val_loss: 0.3069 - val_accuracy: 0.8888\n",
      "Epoch 145/2000\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.2548 - accuracy: 0.9073 - val_loss: 0.3068 - val_accuracy: 0.8896\n",
      "Epoch 146/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2548 - accuracy: 0.9072 - val_loss: 0.3069 - val_accuracy: 0.8888\n",
      "Epoch 147/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2548 - accuracy: 0.9075 - val_loss: 0.3068 - val_accuracy: 0.8906\n",
      "Epoch 148/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2548 - accuracy: 0.9073 - val_loss: 0.3069 - val_accuracy: 0.8890\n",
      "Epoch 149/2000\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.2548 - accuracy: 0.9077 - val_loss: 0.3069 - val_accuracy: 0.8904\n",
      "Epoch 150/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2547 - accuracy: 0.9073 - val_loss: 0.3070 - val_accuracy: 0.8890\n",
      "Epoch 151/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2548 - accuracy: 0.9078 - val_loss: 0.3069 - val_accuracy: 0.8902\n",
      "Epoch 152/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2547 - accuracy: 0.9073 - val_loss: 0.3071 - val_accuracy: 0.8890\n",
      "Epoch 153/2000\n",
      "1/1 [==============================] - 1s 691ms/step - loss: 0.2548 - accuracy: 0.9076 - val_loss: 0.3070 - val_accuracy: 0.8896\n",
      "Epoch 154/2000\n",
      "1/1 [==============================] - 1s 674ms/step - loss: 0.2547 - accuracy: 0.9073 - val_loss: 0.3071 - val_accuracy: 0.8886\n",
      "Epoch 155/2000\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 0.2548 - accuracy: 0.9076 - val_loss: 0.3070 - val_accuracy: 0.8894\n",
      "Epoch 156/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2547 - accuracy: 0.9073 - val_loss: 0.3072 - val_accuracy: 0.8882\n",
      "Epoch 157/2000\n",
      "1/1 [==============================] - 1s 696ms/step - loss: 0.2548 - accuracy: 0.9075 - val_loss: 0.3071 - val_accuracy: 0.8890\n",
      "Epoch 158/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2547 - accuracy: 0.9072 - val_loss: 0.3072 - val_accuracy: 0.8884\n",
      "Epoch 159/2000\n",
      "1/1 [==============================] - 1s 685ms/step - loss: 0.2548 - accuracy: 0.9075 - val_loss: 0.3072 - val_accuracy: 0.8888\n",
      "Epoch 160/2000\n",
      "1/1 [==============================] - 1s 686ms/step - loss: 0.2547 - accuracy: 0.9073 - val_loss: 0.3073 - val_accuracy: 0.8884\n",
      "Epoch 161/2000\n",
      "1/1 [==============================] - 1s 677ms/step - loss: 0.2547 - accuracy: 0.9074 - val_loss: 0.3072 - val_accuracy: 0.8886\n",
      "Epoch 162/2000\n",
      "1/1 [==============================] - 1s 667ms/step - loss: 0.2547 - accuracy: 0.9073 - val_loss: 0.3074 - val_accuracy: 0.8884\n",
      "Epoch 163/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2547 - accuracy: 0.9074 - val_loss: 0.3073 - val_accuracy: 0.8886\n",
      "Epoch 164/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2547 - accuracy: 0.9073 - val_loss: 0.3074 - val_accuracy: 0.8882\n",
      "Epoch 165/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2548 - accuracy: 0.9074 - val_loss: 0.3073 - val_accuracy: 0.8884\n",
      "Epoch 166/2000\n",
      "1/1 [==============================] - 1s 685ms/step - loss: 0.2547 - accuracy: 0.9074 - val_loss: 0.3075 - val_accuracy: 0.8888\n",
      "Epoch 167/2000\n",
      "1/1 [==============================] - 1s 680ms/step - loss: 0.2547 - accuracy: 0.9076 - val_loss: 0.3074 - val_accuracy: 0.8884\n",
      "Epoch 168/2000\n",
      "1/1 [==============================] - 1s 667ms/step - loss: 0.2547 - accuracy: 0.9074 - val_loss: 0.3075 - val_accuracy: 0.8886\n",
      "Epoch 169/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2547 - accuracy: 0.9076 - val_loss: 0.3074 - val_accuracy: 0.8886\n",
      "Epoch 170/2000\n",
      "1/1 [==============================] - 1s 685ms/step - loss: 0.2546 - accuracy: 0.9074 - val_loss: 0.3075 - val_accuracy: 0.8886\n",
      "Epoch 171/2000\n",
      "1/1 [==============================] - 1s 694ms/step - loss: 0.2546 - accuracy: 0.9076 - val_loss: 0.3074 - val_accuracy: 0.8886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/2000\n",
      "1/1 [==============================] - 1s 666ms/step - loss: 0.2546 - accuracy: 0.9075 - val_loss: 0.3075 - val_accuracy: 0.8886\n",
      "Epoch 173/2000\n",
      "1/1 [==============================] - 1s 674ms/step - loss: 0.2546 - accuracy: 0.9076 - val_loss: 0.3074 - val_accuracy: 0.8886\n",
      "Epoch 174/2000\n",
      "1/1 [==============================] - 1s 711ms/step - loss: 0.2545 - accuracy: 0.9075 - val_loss: 0.3075 - val_accuracy: 0.8886\n",
      "Epoch 175/2000\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 0.2545 - accuracy: 0.9076 - val_loss: 0.3074 - val_accuracy: 0.8886\n",
      "Epoch 176/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2544 - accuracy: 0.9075 - val_loss: 0.3075 - val_accuracy: 0.8884\n",
      "Epoch 177/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2545 - accuracy: 0.9077 - val_loss: 0.3074 - val_accuracy: 0.8884\n",
      "Epoch 178/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2544 - accuracy: 0.9075 - val_loss: 0.3076 - val_accuracy: 0.8884\n",
      "Epoch 179/2000\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 0.2544 - accuracy: 0.9077 - val_loss: 0.3073 - val_accuracy: 0.8884\n",
      "Epoch 180/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2543 - accuracy: 0.9076 - val_loss: 0.3075 - val_accuracy: 0.8886\n",
      "Epoch 181/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2544 - accuracy: 0.9076 - val_loss: 0.3073 - val_accuracy: 0.8884\n",
      "Epoch 182/2000\n",
      "1/1 [==============================] - 1s 664ms/step - loss: 0.2542 - accuracy: 0.9076 - val_loss: 0.3075 - val_accuracy: 0.8886\n",
      "Epoch 183/2000\n",
      "1/1 [==============================] - 1s 669ms/step - loss: 0.2543 - accuracy: 0.9077 - val_loss: 0.3073 - val_accuracy: 0.8884\n",
      "Epoch 184/2000\n",
      "1/1 [==============================] - 1s 692ms/step - loss: 0.2542 - accuracy: 0.9077 - val_loss: 0.3075 - val_accuracy: 0.8888\n",
      "Epoch 185/2000\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 0.2542 - accuracy: 0.9078 - val_loss: 0.3073 - val_accuracy: 0.8884\n",
      "Epoch 186/2000\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 0.2541 - accuracy: 0.9077 - val_loss: 0.3075 - val_accuracy: 0.8888\n",
      "Epoch 187/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2541 - accuracy: 0.9079 - val_loss: 0.3073 - val_accuracy: 0.8884\n",
      "Epoch 188/2000\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 0.2540 - accuracy: 0.9077 - val_loss: 0.3075 - val_accuracy: 0.8888\n",
      "Epoch 189/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2541 - accuracy: 0.9079 - val_loss: 0.3072 - val_accuracy: 0.8884\n",
      "Epoch 190/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2539 - accuracy: 0.9077 - val_loss: 0.3075 - val_accuracy: 0.8888\n",
      "Epoch 191/2000\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.2540 - accuracy: 0.9079 - val_loss: 0.3072 - val_accuracy: 0.8882\n",
      "Epoch 192/2000\n",
      "1/1 [==============================] - 1s 714ms/step - loss: 0.2539 - accuracy: 0.9077 - val_loss: 0.3075 - val_accuracy: 0.8888\n",
      "Epoch 193/2000\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.2539 - accuracy: 0.9079 - val_loss: 0.3072 - val_accuracy: 0.8882\n",
      "Epoch 194/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2538 - accuracy: 0.9078 - val_loss: 0.3075 - val_accuracy: 0.8886\n",
      "Epoch 195/2000\n",
      "1/1 [==============================] - 1s 677ms/step - loss: 0.2538 - accuracy: 0.9079 - val_loss: 0.3072 - val_accuracy: 0.8882\n",
      "Epoch 196/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2537 - accuracy: 0.9078 - val_loss: 0.3075 - val_accuracy: 0.8886\n",
      "Epoch 197/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2538 - accuracy: 0.9079 - val_loss: 0.3072 - val_accuracy: 0.8882\n",
      "Epoch 198/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2537 - accuracy: 0.9078 - val_loss: 0.3075 - val_accuracy: 0.8888\n",
      "Epoch 199/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2537 - accuracy: 0.9080 - val_loss: 0.3072 - val_accuracy: 0.8882\n",
      "Epoch 200/2000\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.2536 - accuracy: 0.9079 - val_loss: 0.3075 - val_accuracy: 0.8888\n",
      "Epoch 201/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2537 - accuracy: 0.9079 - val_loss: 0.3072 - val_accuracy: 0.8884\n",
      "Epoch 202/2000\n",
      "1/1 [==============================] - 1s 668ms/step - loss: 0.2536 - accuracy: 0.9079 - val_loss: 0.3075 - val_accuracy: 0.8886\n",
      "Epoch 203/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2536 - accuracy: 0.9080 - val_loss: 0.3072 - val_accuracy: 0.8884\n",
      "Epoch 204/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2535 - accuracy: 0.9079 - val_loss: 0.3075 - val_accuracy: 0.8884\n",
      "Epoch 205/2000\n",
      "1/1 [==============================] - 1s 671ms/step - loss: 0.2536 - accuracy: 0.9081 - val_loss: 0.3072 - val_accuracy: 0.8884\n",
      "Epoch 206/2000\n",
      "1/1 [==============================] - 1s 685ms/step - loss: 0.2535 - accuracy: 0.9078 - val_loss: 0.3075 - val_accuracy: 0.8884\n",
      "Epoch 207/2000\n",
      "1/1 [==============================] - 1s 680ms/step - loss: 0.2536 - accuracy: 0.9081 - val_loss: 0.3072 - val_accuracy: 0.8880\n",
      "Epoch 208/2000\n",
      "1/1 [==============================] - 1s 685ms/step - loss: 0.2534 - accuracy: 0.9078 - val_loss: 0.3076 - val_accuracy: 0.8884\n",
      "Epoch 209/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2535 - accuracy: 0.9081 - val_loss: 0.3072 - val_accuracy: 0.8880\n",
      "Epoch 210/2000\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 0.2534 - accuracy: 0.9078 - val_loss: 0.3076 - val_accuracy: 0.8884\n",
      "Epoch 211/2000\n",
      "1/1 [==============================] - 1s 674ms/step - loss: 0.2535 - accuracy: 0.9081 - val_loss: 0.3072 - val_accuracy: 0.8880\n",
      "Epoch 212/2000\n",
      "1/1 [==============================] - 1s 703ms/step - loss: 0.2533 - accuracy: 0.9078 - val_loss: 0.3076 - val_accuracy: 0.8882\n",
      "Epoch 213/2000\n",
      "1/1 [==============================] - 1s 672ms/step - loss: 0.2534 - accuracy: 0.9081 - val_loss: 0.3072 - val_accuracy: 0.8882\n",
      "Epoch 214/2000\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.2532 - accuracy: 0.9079 - val_loss: 0.3076 - val_accuracy: 0.8882\n",
      "Epoch 215/2000\n",
      "1/1 [==============================] - 1s 664ms/step - loss: 0.2533 - accuracy: 0.9081 - val_loss: 0.3072 - val_accuracy: 0.8882\n",
      "Epoch 216/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2531 - accuracy: 0.9079 - val_loss: 0.3075 - val_accuracy: 0.8882\n",
      "Epoch 217/2000\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 0.2532 - accuracy: 0.9081 - val_loss: 0.3072 - val_accuracy: 0.8882\n",
      "Epoch 218/2000\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 0.2531 - accuracy: 0.9079 - val_loss: 0.3075 - val_accuracy: 0.8884\n",
      "Epoch 219/2000\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 0.2532 - accuracy: 0.9082 - val_loss: 0.3071 - val_accuracy: 0.8882\n",
      "Epoch 220/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2530 - accuracy: 0.9080 - val_loss: 0.3075 - val_accuracy: 0.8884\n",
      "Epoch 221/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2531 - accuracy: 0.9082 - val_loss: 0.3071 - val_accuracy: 0.8886\n",
      "Epoch 222/2000\n",
      "1/1 [==============================] - 1s 697ms/step - loss: 0.2529 - accuracy: 0.9081 - val_loss: 0.3074 - val_accuracy: 0.8884\n",
      "Epoch 223/2000\n",
      "1/1 [==============================] - 1s 685ms/step - loss: 0.2530 - accuracy: 0.9083 - val_loss: 0.3071 - val_accuracy: 0.8886\n",
      "Epoch 224/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2528 - accuracy: 0.9081 - val_loss: 0.3074 - val_accuracy: 0.8882\n",
      "Epoch 225/2000\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 0.2529 - accuracy: 0.9082 - val_loss: 0.3071 - val_accuracy: 0.8886\n",
      "Epoch 226/2000\n",
      "1/1 [==============================] - 1s 666ms/step - loss: 0.2527 - accuracy: 0.9081 - val_loss: 0.3074 - val_accuracy: 0.8884\n",
      "Epoch 227/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2528 - accuracy: 0.9082 - val_loss: 0.3070 - val_accuracy: 0.8886\n",
      "Epoch 228/2000\n",
      "1/1 [==============================] - 1s 697ms/step - loss: 0.2526 - accuracy: 0.9081 - val_loss: 0.3074 - val_accuracy: 0.8884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2527 - accuracy: 0.9082 - val_loss: 0.3070 - val_accuracy: 0.8888\n",
      "Epoch 230/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2526 - accuracy: 0.9081 - val_loss: 0.3074 - val_accuracy: 0.8884\n",
      "Epoch 231/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2527 - accuracy: 0.9082 - val_loss: 0.3070 - val_accuracy: 0.8888\n",
      "Epoch 232/2000\n",
      "1/1 [==============================] - 1s 686ms/step - loss: 0.2525 - accuracy: 0.9082 - val_loss: 0.3074 - val_accuracy: 0.8886\n",
      "Epoch 233/2000\n",
      "1/1 [==============================] - 1s 679ms/step - loss: 0.2526 - accuracy: 0.9082 - val_loss: 0.3071 - val_accuracy: 0.8888\n",
      "Epoch 234/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2525 - accuracy: 0.9083 - val_loss: 0.3074 - val_accuracy: 0.8884\n",
      "Epoch 235/2000\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.2526 - accuracy: 0.9081 - val_loss: 0.3071 - val_accuracy: 0.8888\n",
      "Epoch 236/2000\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.2524 - accuracy: 0.9083 - val_loss: 0.3074 - val_accuracy: 0.8884\n",
      "Epoch 237/2000\n",
      "1/1 [==============================] - 1s 667ms/step - loss: 0.2525 - accuracy: 0.9081 - val_loss: 0.3071 - val_accuracy: 0.8886\n",
      "Epoch 238/2000\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.2524 - accuracy: 0.9083 - val_loss: 0.3074 - val_accuracy: 0.8884\n",
      "Epoch 239/2000\n",
      "1/1 [==============================] - 1s 685ms/step - loss: 0.2525 - accuracy: 0.9082 - val_loss: 0.3071 - val_accuracy: 0.8886\n",
      "Epoch 240/2000\n",
      "1/1 [==============================] - 1s 690ms/step - loss: 0.2523 - accuracy: 0.9084 - val_loss: 0.3074 - val_accuracy: 0.8884\n",
      "Epoch 241/2000\n",
      "1/1 [==============================] - 1s 668ms/step - loss: 0.2524 - accuracy: 0.9082 - val_loss: 0.3071 - val_accuracy: 0.8886\n",
      "Epoch 242/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2522 - accuracy: 0.9084 - val_loss: 0.3074 - val_accuracy: 0.8882\n",
      "Epoch 243/2000\n",
      "1/1 [==============================] - 1s 671ms/step - loss: 0.2524 - accuracy: 0.9083 - val_loss: 0.3071 - val_accuracy: 0.8886\n",
      "Epoch 244/2000\n",
      "1/1 [==============================] - 1s 714ms/step - loss: 0.2522 - accuracy: 0.9085 - val_loss: 0.3074 - val_accuracy: 0.8882\n",
      "Epoch 245/2000\n",
      "1/1 [==============================] - 1s 716ms/step - loss: 0.2523 - accuracy: 0.9083 - val_loss: 0.3071 - val_accuracy: 0.8884\n",
      "Epoch 246/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2521 - accuracy: 0.9085 - val_loss: 0.3074 - val_accuracy: 0.8882\n",
      "Epoch 247/2000\n",
      "1/1 [==============================] - 1s 680ms/step - loss: 0.2522 - accuracy: 0.9082 - val_loss: 0.3071 - val_accuracy: 0.8884\n",
      "Epoch 1/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2548 - accuracy: 0.9073 - val_loss: 0.3064 - val_accuracy: 0.8896\n",
      "Epoch 2/2000\n",
      "1/1 [==============================] - 1s 629ms/step - loss: 0.2542 - accuracy: 0.9078 - val_loss: 0.3062 - val_accuracy: 0.8894\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2540 - accuracy: 0.9079 - val_loss: 0.3062 - val_accuracy: 0.8894\n",
      "Epoch 4/2000\n",
      "1/1 [==============================] - 1s 690ms/step - loss: 0.2540 - accuracy: 0.9079 - val_loss: 0.3062 - val_accuracy: 0.8894\n",
      "Epoch 5/2000\n",
      "1/1 [==============================] - 1s 676ms/step - loss: 0.2539 - accuracy: 0.9079 - val_loss: 0.3062 - val_accuracy: 0.8892\n",
      "Epoch 6/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2539 - accuracy: 0.9080 - val_loss: 0.3062 - val_accuracy: 0.8894\n",
      "Epoch 7/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2539 - accuracy: 0.9080 - val_loss: 0.3061 - val_accuracy: 0.8894\n",
      "Epoch 8/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2538 - accuracy: 0.9080 - val_loss: 0.3061 - val_accuracy: 0.8894\n",
      "Epoch 9/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2538 - accuracy: 0.9080 - val_loss: 0.3061 - val_accuracy: 0.8894\n",
      "Epoch 10/2000\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.2538 - accuracy: 0.9080 - val_loss: 0.3061 - val_accuracy: 0.8894\n",
      "Epoch 11/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2537 - accuracy: 0.9080 - val_loss: 0.3061 - val_accuracy: 0.8894\n",
      "Epoch 12/2000\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 0.2537 - accuracy: 0.9080 - val_loss: 0.3061 - val_accuracy: 0.8894\n",
      "Epoch 13/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2537 - accuracy: 0.9080 - val_loss: 0.3061 - val_accuracy: 0.8894\n",
      "Epoch 14/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2536 - accuracy: 0.9081 - val_loss: 0.3061 - val_accuracy: 0.8894\n",
      "Epoch 15/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2536 - accuracy: 0.9081 - val_loss: 0.3061 - val_accuracy: 0.8894\n",
      "Epoch 16/2000\n",
      "1/1 [==============================] - 1s 686ms/step - loss: 0.2536 - accuracy: 0.9081 - val_loss: 0.3060 - val_accuracy: 0.8894\n",
      "Epoch 17/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2535 - accuracy: 0.9081 - val_loss: 0.3060 - val_accuracy: 0.8894\n",
      "Epoch 18/2000\n",
      "1/1 [==============================] - 1s 680ms/step - loss: 0.2535 - accuracy: 0.9081 - val_loss: 0.3060 - val_accuracy: 0.8894\n",
      "Epoch 19/2000\n",
      "1/1 [==============================] - 1s 697ms/step - loss: 0.2535 - accuracy: 0.9081 - val_loss: 0.3060 - val_accuracy: 0.8894\n",
      "Epoch 20/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2534 - accuracy: 0.9081 - val_loss: 0.3060 - val_accuracy: 0.8894\n",
      "Epoch 21/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2534 - accuracy: 0.9081 - val_loss: 0.3060 - val_accuracy: 0.8894\n",
      "Epoch 22/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2533 - accuracy: 0.9081 - val_loss: 0.3060 - val_accuracy: 0.8894\n",
      "Epoch 23/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2533 - accuracy: 0.9081 - val_loss: 0.3060 - val_accuracy: 0.8894\n",
      "Epoch 24/2000\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 0.2533 - accuracy: 0.9081 - val_loss: 0.3060 - val_accuracy: 0.8894\n",
      "Epoch 25/2000\n",
      "1/1 [==============================] - 1s 714ms/step - loss: 0.2532 - accuracy: 0.9081 - val_loss: 0.3059 - val_accuracy: 0.8894\n",
      "Epoch 26/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2532 - accuracy: 0.9081 - val_loss: 0.3059 - val_accuracy: 0.8894\n",
      "Epoch 27/2000\n",
      "1/1 [==============================] - 1s 697ms/step - loss: 0.2532 - accuracy: 0.9082 - val_loss: 0.3059 - val_accuracy: 0.8894\n",
      "Epoch 28/2000\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 0.2531 - accuracy: 0.9082 - val_loss: 0.3059 - val_accuracy: 0.8894\n",
      "Epoch 29/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2531 - accuracy: 0.9082 - val_loss: 0.3059 - val_accuracy: 0.8894\n",
      "Epoch 30/2000\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.2531 - accuracy: 0.9082 - val_loss: 0.3059 - val_accuracy: 0.8894\n",
      "Epoch 31/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2530 - accuracy: 0.9082 - val_loss: 0.3059 - val_accuracy: 0.8894\n",
      "Epoch 32/2000\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.2530 - accuracy: 0.9082 - val_loss: 0.3059 - val_accuracy: 0.8894\n",
      "Epoch 33/2000\n",
      "1/1 [==============================] - 1s 716ms/step - loss: 0.2530 - accuracy: 0.9082 - val_loss: 0.3059 - val_accuracy: 0.8894\n",
      "Epoch 34/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2529 - accuracy: 0.9082 - val_loss: 0.3059 - val_accuracy: 0.8894\n",
      "Epoch 35/2000\n",
      "1/1 [==============================] - 1s 689ms/step - loss: 0.2529 - accuracy: 0.9082 - val_loss: 0.3058 - val_accuracy: 0.8894\n",
      "Epoch 36/2000\n",
      "1/1 [==============================] - 1s 710ms/step - loss: 0.2529 - accuracy: 0.9082 - val_loss: 0.3058 - val_accuracy: 0.8894\n",
      "Epoch 37/2000\n",
      "1/1 [==============================] - 1s 688ms/step - loss: 0.2528 - accuracy: 0.9083 - val_loss: 0.3058 - val_accuracy: 0.8896\n",
      "Epoch 38/2000\n",
      "1/1 [==============================] - 1s 674ms/step - loss: 0.2528 - accuracy: 0.9083 - val_loss: 0.3058 - val_accuracy: 0.8896\n",
      "Epoch 39/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 699ms/step - loss: 0.2528 - accuracy: 0.9083 - val_loss: 0.3058 - val_accuracy: 0.8896\n",
      "Epoch 40/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2527 - accuracy: 0.9083 - val_loss: 0.3058 - val_accuracy: 0.8896\n",
      "Epoch 41/2000\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 0.2527 - accuracy: 0.9084 - val_loss: 0.3058 - val_accuracy: 0.8896\n",
      "Epoch 42/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2527 - accuracy: 0.9084 - val_loss: 0.3058 - val_accuracy: 0.8896\n",
      "Epoch 43/2000\n",
      "1/1 [==============================] - 1s 691ms/step - loss: 0.2526 - accuracy: 0.9084 - val_loss: 0.3058 - val_accuracy: 0.8896\n",
      "Epoch 44/2000\n",
      "1/1 [==============================] - 1s 677ms/step - loss: 0.2526 - accuracy: 0.9084 - val_loss: 0.3058 - val_accuracy: 0.8898\n",
      "Epoch 45/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2525 - accuracy: 0.9084 - val_loss: 0.3058 - val_accuracy: 0.8898\n",
      "Epoch 46/2000\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.2525 - accuracy: 0.9084 - val_loss: 0.3057 - val_accuracy: 0.8898\n",
      "Epoch 47/2000\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 0.2525 - accuracy: 0.9084 - val_loss: 0.3057 - val_accuracy: 0.8898\n",
      "Epoch 48/2000\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 0.2524 - accuracy: 0.9085 - val_loss: 0.3057 - val_accuracy: 0.8898\n",
      "Epoch 49/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2524 - accuracy: 0.9085 - val_loss: 0.3057 - val_accuracy: 0.8898\n",
      "Epoch 50/2000\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 0.2524 - accuracy: 0.9085 - val_loss: 0.3057 - val_accuracy: 0.8898\n",
      "Epoch 51/2000\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.2523 - accuracy: 0.9085 - val_loss: 0.3057 - val_accuracy: 0.8898\n",
      "Epoch 52/2000\n",
      "1/1 [==============================] - 1s 691ms/step - loss: 0.2523 - accuracy: 0.9085 - val_loss: 0.3057 - val_accuracy: 0.8898\n",
      "Epoch 53/2000\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.2523 - accuracy: 0.9085 - val_loss: 0.3057 - val_accuracy: 0.8898\n",
      "Epoch 54/2000\n",
      "1/1 [==============================] - 1s 702ms/step - loss: 0.2522 - accuracy: 0.9086 - val_loss: 0.3057 - val_accuracy: 0.8900\n",
      "Epoch 55/2000\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 0.2522 - accuracy: 0.9086 - val_loss: 0.3057 - val_accuracy: 0.8898\n",
      "Epoch 56/2000\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.2522 - accuracy: 0.9086 - val_loss: 0.3057 - val_accuracy: 0.8900\n",
      "Epoch 57/2000\n",
      "1/1 [==============================] - 1s 703ms/step - loss: 0.2521 - accuracy: 0.9087 - val_loss: 0.3056 - val_accuracy: 0.8898\n",
      "Epoch 58/2000\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 0.2521 - accuracy: 0.9086 - val_loss: 0.3056 - val_accuracy: 0.8900\n",
      "Epoch 59/2000\n",
      "1/1 [==============================] - 1s 706ms/step - loss: 0.2521 - accuracy: 0.9087 - val_loss: 0.3056 - val_accuracy: 0.8900\n",
      "Epoch 60/2000\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 0.2520 - accuracy: 0.9087 - val_loss: 0.3056 - val_accuracy: 0.8900\n",
      "Epoch 61/2000\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 0.2520 - accuracy: 0.9088 - val_loss: 0.3056 - val_accuracy: 0.8900\n",
      "Epoch 62/2000\n",
      "1/1 [==============================] - 1s 702ms/step - loss: 0.2520 - accuracy: 0.9088 - val_loss: 0.3056 - val_accuracy: 0.8902\n",
      "Epoch 63/2000\n",
      "1/1 [==============================] - 1s 714ms/step - loss: 0.2519 - accuracy: 0.9088 - val_loss: 0.3056 - val_accuracy: 0.8902\n",
      "Epoch 64/2000\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 0.2519 - accuracy: 0.9088 - val_loss: 0.3056 - val_accuracy: 0.8902\n",
      "Epoch 65/2000\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 0.2519 - accuracy: 0.9088 - val_loss: 0.3056 - val_accuracy: 0.8904\n",
      "Epoch 66/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2518 - accuracy: 0.9089 - val_loss: 0.3056 - val_accuracy: 0.8902\n",
      "Epoch 67/2000\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 0.2518 - accuracy: 0.9089 - val_loss: 0.3055 - val_accuracy: 0.8904\n",
      "Epoch 68/2000\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 0.2518 - accuracy: 0.9089 - val_loss: 0.3055 - val_accuracy: 0.8902\n",
      "Epoch 69/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2517 - accuracy: 0.9089 - val_loss: 0.3055 - val_accuracy: 0.8904\n",
      "Epoch 70/2000\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 0.2517 - accuracy: 0.9089 - val_loss: 0.3055 - val_accuracy: 0.8906\n",
      "Epoch 71/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2517 - accuracy: 0.9089 - val_loss: 0.3055 - val_accuracy: 0.8904\n",
      "Epoch 72/2000\n",
      "1/1 [==============================] - 1s 693ms/step - loss: 0.2516 - accuracy: 0.9089 - val_loss: 0.3055 - val_accuracy: 0.8906\n",
      "Epoch 73/2000\n",
      "1/1 [==============================] - 1s 734ms/step - loss: 0.2516 - accuracy: 0.9089 - val_loss: 0.3055 - val_accuracy: 0.8904\n",
      "Epoch 74/2000\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.2516 - accuracy: 0.9090 - val_loss: 0.3055 - val_accuracy: 0.8906\n",
      "Epoch 75/2000\n",
      "1/1 [==============================] - 1s 694ms/step - loss: 0.2515 - accuracy: 0.9089 - val_loss: 0.3055 - val_accuracy: 0.8904\n",
      "Epoch 76/2000\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 0.2515 - accuracy: 0.9091 - val_loss: 0.3055 - val_accuracy: 0.8906\n",
      "Epoch 77/2000\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.2514 - accuracy: 0.9090 - val_loss: 0.3055 - val_accuracy: 0.8904\n",
      "Epoch 78/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2514 - accuracy: 0.9090 - val_loss: 0.3055 - val_accuracy: 0.8906\n",
      "Epoch 79/2000\n",
      "1/1 [==============================] - 1s 666ms/step - loss: 0.2514 - accuracy: 0.9090 - val_loss: 0.3054 - val_accuracy: 0.8904\n",
      "Epoch 80/2000\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.2513 - accuracy: 0.9090 - val_loss: 0.3054 - val_accuracy: 0.8906\n",
      "Epoch 81/2000\n",
      "1/1 [==============================] - 1s 680ms/step - loss: 0.2513 - accuracy: 0.9090 - val_loss: 0.3054 - val_accuracy: 0.8904\n",
      "Epoch 82/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2513 - accuracy: 0.9090 - val_loss: 0.3054 - val_accuracy: 0.8906\n",
      "Epoch 83/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2512 - accuracy: 0.9090 - val_loss: 0.3054 - val_accuracy: 0.8906\n",
      "Epoch 84/2000\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.2512 - accuracy: 0.9090 - val_loss: 0.3054 - val_accuracy: 0.8906\n",
      "Epoch 85/2000\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.2512 - accuracy: 0.9090 - val_loss: 0.3054 - val_accuracy: 0.8906\n",
      "Epoch 86/2000\n",
      "1/1 [==============================] - 1s 666ms/step - loss: 0.2511 - accuracy: 0.9091 - val_loss: 0.3054 - val_accuracy: 0.8906\n",
      "Epoch 87/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2511 - accuracy: 0.9090 - val_loss: 0.3054 - val_accuracy: 0.8906\n",
      "Epoch 88/2000\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 0.2511 - accuracy: 0.9090 - val_loss: 0.3054 - val_accuracy: 0.8906\n",
      "Epoch 89/2000\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.2510 - accuracy: 0.9091 - val_loss: 0.3053 - val_accuracy: 0.8906\n",
      "Epoch 90/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2510 - accuracy: 0.9091 - val_loss: 0.3053 - val_accuracy: 0.8906\n",
      "Epoch 91/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2510 - accuracy: 0.9091 - val_loss: 0.3053 - val_accuracy: 0.8908\n",
      "Epoch 92/2000\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.2509 - accuracy: 0.9091 - val_loss: 0.3053 - val_accuracy: 0.8908\n",
      "Epoch 93/2000\n",
      "1/1 [==============================] - 1s 679ms/step - loss: 0.2509 - accuracy: 0.9091 - val_loss: 0.3053 - val_accuracy: 0.8908\n",
      "Epoch 94/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2509 - accuracy: 0.9091 - val_loss: 0.3053 - val_accuracy: 0.8908\n",
      "Epoch 95/2000\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.2508 - accuracy: 0.9091 - val_loss: 0.3053 - val_accuracy: 0.8910\n",
      "Epoch 96/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2508 - accuracy: 0.9091 - val_loss: 0.3053 - val_accuracy: 0.8908\n",
      "Epoch 97/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2508 - accuracy: 0.9091 - val_loss: 0.3053 - val_accuracy: 0.8910\n",
      "Epoch 98/2000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.2507 - accuracy: 0.9091 - val_loss: 0.3053 - val_accuracy: 0.8908\n",
      "Epoch 99/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2507 - accuracy: 0.9091 - val_loss: 0.3052 - val_accuracy: 0.8910\n",
      "Epoch 100/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2507 - accuracy: 0.9090 - val_loss: 0.3052 - val_accuracy: 0.8908\n",
      "Epoch 101/2000\n",
      "1/1 [==============================] - 1s 669ms/step - loss: 0.2506 - accuracy: 0.9091 - val_loss: 0.3052 - val_accuracy: 0.8910\n",
      "Epoch 102/2000\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.2506 - accuracy: 0.9091 - val_loss: 0.3052 - val_accuracy: 0.8910\n",
      "Epoch 103/2000\n",
      "1/1 [==============================] - 1s 668ms/step - loss: 0.2506 - accuracy: 0.9091 - val_loss: 0.3052 - val_accuracy: 0.8914\n",
      "Epoch 104/2000\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2505 - accuracy: 0.9092 - val_loss: 0.3052 - val_accuracy: 0.8910\n",
      "Epoch 105/2000\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.2505 - accuracy: 0.9092 - val_loss: 0.3052 - val_accuracy: 0.8912\n",
      "Epoch 106/2000\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 0.2505 - accuracy: 0.9092 - val_loss: 0.3052 - val_accuracy: 0.8912\n",
      "Epoch 107/2000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2504 - accuracy: 0.9092 - val_loss: 0.3052 - val_accuracy: 0.8912\n",
      "Epoch 108/2000\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.2504 - accuracy: 0.9092 - val_loss: 0.3052 - val_accuracy: 0.8912\n",
      "Epoch 109/2000\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 0.2504 - accuracy: 0.9092 - val_loss: 0.3051 - val_accuracy: 0.8912\n",
      "Epoch 110/2000\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 0.2503 - accuracy: 0.9092 - val_loss: 0.3051 - val_accuracy: 0.8912\n",
      "Epoch 111/2000\n",
      "1/1 [==============================] - 1s 736ms/step - loss: 0.2503 - accuracy: 0.9093 - val_loss: 0.3051 - val_accuracy: 0.8912\n",
      "Epoch 112/2000\n",
      "1/1 [==============================] - 1s 714ms/step - loss: 0.2503 - accuracy: 0.9093 - val_loss: 0.3051 - val_accuracy: 0.8912\n",
      "Epoch 113/2000\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 0.2502 - accuracy: 0.9093 - val_loss: 0.3051 - val_accuracy: 0.8912\n",
      "Epoch 114/2000\n",
      "1/1 [==============================] - 1s 714ms/step - loss: 0.2502 - accuracy: 0.9094 - val_loss: 0.3051 - val_accuracy: 0.8912\n",
      "Epoch 115/2000\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.2502 - accuracy: 0.9093 - val_loss: 0.3051 - val_accuracy: 0.8912\n",
      "Epoch 116/2000\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.2501 - accuracy: 0.9094 - val_loss: 0.3051 - val_accuracy: 0.8912\n",
      "Epoch 117/2000\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 0.2501 - accuracy: 0.9094 - val_loss: 0.3051 - val_accuracy: 0.8912\n",
      "Epoch 118/2000\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.2500 - accuracy: 0.9094 - val_loss: 0.3051 - val_accuracy: 0.8912\n",
      "Epoch 119/2000\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.2500 - accuracy: 0.9094 - val_loss: 0.3050 - val_accuracy: 0.8912\n",
      "Epoch 120/2000\n",
      "1/1 [==============================] - 1s 696ms/step - loss: 0.2500 - accuracy: 0.9094 - val_loss: 0.3050 - val_accuracy: 0.8912\n",
      "Epoch 121/2000\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 0.2499 - accuracy: 0.9095 - val_loss: 0.3050 - val_accuracy: 0.8912\n",
      "Epoch 122/2000\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.2499 - accuracy: 0.9095 - val_loss: 0.3050 - val_accuracy: 0.8912\n",
      "Epoch 123/2000\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 0.2499 - accuracy: 0.9095 - val_loss: 0.3050 - val_accuracy: 0.8912\n",
      "Epoch 124/2000\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 0.2498 - accuracy: 0.9096 - val_loss: 0.3050 - val_accuracy: 0.8912\n",
      "Epoch 125/2000\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.2498 - accuracy: 0.9095 - val_loss: 0.3050 - val_accuracy: 0.8912\n",
      "Epoch 126/2000\n",
      "1/1 [==============================] - 1s 733ms/step - loss: 0.2498 - accuracy: 0.9095 - val_loss: 0.3050 - val_accuracy: 0.8912\n",
      "Epoch 127/2000\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 0.2497 - accuracy: 0.9096 - val_loss: 0.3050 - val_accuracy: 0.8912\n",
      "Epoch 128/2000\n",
      "1/1 [==============================] - 1s 781ms/step - loss: 0.2497 - accuracy: 0.9096 - val_loss: 0.3050 - val_accuracy: 0.8912\n",
      "Epoch 129/2000\n",
      "1/1 [==============================] - 1s 801ms/step - loss: 0.2497 - accuracy: 0.9096 - val_loss: 0.3049 - val_accuracy: 0.8912\n",
      "Epoch 130/2000\n",
      "1/1 [==============================] - 1s 734ms/step - loss: 0.2496 - accuracy: 0.9097 - val_loss: 0.3049 - val_accuracy: 0.8912\n",
      "Epoch 131/2000\n",
      "1/1 [==============================] - 1s 716ms/step - loss: 0.2496 - accuracy: 0.9097 - val_loss: 0.3049 - val_accuracy: 0.8912\n",
      "Epoch 132/2000\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 0.2496 - accuracy: 0.9097 - val_loss: 0.3049 - val_accuracy: 0.8912\n",
      "Epoch 133/2000\n",
      "1/1 [==============================] - 1s 714ms/step - loss: 0.2495 - accuracy: 0.9097 - val_loss: 0.3049 - val_accuracy: 0.8912\n",
      "Epoch 134/2000\n",
      "1/1 [==============================] - 1s 736ms/step - loss: 0.2495 - accuracy: 0.9097 - val_loss: 0.3049 - val_accuracy: 0.8912\n",
      "Epoch 135/2000\n",
      "1/1 [==============================] - 1s 714ms/step - loss: 0.2495 - accuracy: 0.9097 - val_loss: 0.3049 - val_accuracy: 0.8912\n",
      "Epoch 136/2000\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 0.2494 - accuracy: 0.9097 - val_loss: 0.3049 - val_accuracy: 0.8912\n",
      "Epoch 137/2000\n",
      "1/1 [==============================] - 1s 714ms/step - loss: 0.2494 - accuracy: 0.9097 - val_loss: 0.3049 - val_accuracy: 0.8912\n",
      "Epoch 138/2000\n",
      "1/1 [==============================] - 1s 716ms/step - loss: 0.2494 - accuracy: 0.9098 - val_loss: 0.3049 - val_accuracy: 0.8912\n",
      "Epoch 139/2000\n",
      "1/1 [==============================] - 1s 702ms/step - loss: 0.2493 - accuracy: 0.9098 - val_loss: 0.3048 - val_accuracy: 0.8912\n",
      "Epoch 140/2000\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 0.2493 - accuracy: 0.9098 - val_loss: 0.3048 - val_accuracy: 0.8912\n",
      "Epoch 141/2000\n",
      "1/1 [==============================] - 1s 705ms/step - loss: 0.2493 - accuracy: 0.9098 - val_loss: 0.3048 - val_accuracy: 0.8912\n",
      "Epoch 142/2000\n",
      "1/1 [==============================] - 1s 711ms/step - loss: 0.2492 - accuracy: 0.9098 - val_loss: 0.3048 - val_accuracy: 0.8914\n",
      "Epoch 143/2000\n",
      "1/1 [==============================] - 1s 732ms/step - loss: 0.2492 - accuracy: 0.9098 - val_loss: 0.3048 - val_accuracy: 0.8914\n",
      "Epoch 144/2000\n",
      "1/1 [==============================] - 1s 716ms/step - loss: 0.2492 - accuracy: 0.9098 - val_loss: 0.3048 - val_accuracy: 0.8914\n",
      "Epoch 145/2000\n",
      "1/1 [==============================] - 1s 745ms/step - loss: 0.2491 - accuracy: 0.9099 - val_loss: 0.3048 - val_accuracy: 0.8914\n",
      "Epoch 146/2000\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 0.2491 - accuracy: 0.9099 - val_loss: 0.3048 - val_accuracy: 0.8914\n",
      "Epoch 147/2000\n",
      "1/1 [==============================] - 1s 733ms/step - loss: 0.2491 - accuracy: 0.9099 - val_loss: 0.3048 - val_accuracy: 0.8914\n",
      "Epoch 148/2000\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 0.2490 - accuracy: 0.9099 - val_loss: 0.3048 - val_accuracy: 0.8914\n",
      "Epoch 149/2000\n",
      "1/1 [==============================] - 1s 716ms/step - loss: 0.2490 - accuracy: 0.9099 - val_loss: 0.3047 - val_accuracy: 0.8916\n",
      "Epoch 150/2000\n",
      "1/1 [==============================] - 1s 730ms/step - loss: 0.2490 - accuracy: 0.9099 - val_loss: 0.3047 - val_accuracy: 0.8914\n",
      "Epoch 151/2000\n",
      "1/1 [==============================] - 1s 716ms/step - loss: 0.2489 - accuracy: 0.9099 - val_loss: 0.3047 - val_accuracy: 0.8916\n",
      "Epoch 152/2000\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 0.2489 - accuracy: 0.9100 - val_loss: 0.3047 - val_accuracy: 0.8916\n",
      "Epoch 153/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 734ms/step - loss: 0.2489 - accuracy: 0.9099 - val_loss: 0.3047 - val_accuracy: 0.8916\n",
      "Epoch 154/2000\n",
      "1/1 [==============================] - 1s 711ms/step - loss: 0.2488 - accuracy: 0.9100 - val_loss: 0.3047 - val_accuracy: 0.8918\n",
      "Epoch 155/2000\n",
      "1/1 [==============================] - 1s 731ms/step - loss: 0.2488 - accuracy: 0.9100 - val_loss: 0.3047 - val_accuracy: 0.8916\n",
      "Epoch 156/2000\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 0.2488 - accuracy: 0.9100 - val_loss: 0.3047 - val_accuracy: 0.8918\n",
      "Epoch 157/2000\n",
      "1/1 [==============================] - 1s 733ms/step - loss: 0.2487 - accuracy: 0.9100 - val_loss: 0.3047 - val_accuracy: 0.8916\n",
      "Epoch 158/2000\n",
      "1/1 [==============================] - 1s 731ms/step - loss: 0.2487 - accuracy: 0.9100 - val_loss: 0.3047 - val_accuracy: 0.8918\n",
      "Epoch 159/2000\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 0.2487 - accuracy: 0.9101 - val_loss: 0.3046 - val_accuracy: 0.8918\n",
      "Epoch 160/2000\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 0.2486 - accuracy: 0.9101 - val_loss: 0.3047 - val_accuracy: 0.8918\n",
      "Epoch 161/2000\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 0.2486 - accuracy: 0.9101 - val_loss: 0.3046 - val_accuracy: 0.8916\n",
      "Epoch 162/2000\n",
      "1/1 [==============================] - 1s 708ms/step - loss: 0.2486 - accuracy: 0.9101 - val_loss: 0.3046 - val_accuracy: 0.8918\n",
      "Epoch 163/2000\n",
      "1/1 [==============================] - 1s 733ms/step - loss: 0.2485 - accuracy: 0.9101 - val_loss: 0.3046 - val_accuracy: 0.8916\n",
      "Epoch 164/2000\n",
      "1/1 [==============================] - 1s 716ms/step - loss: 0.2485 - accuracy: 0.9102 - val_loss: 0.3046 - val_accuracy: 0.8918\n",
      "Epoch 165/2000\n",
      "1/1 [==============================] - 1s 708ms/step - loss: 0.2485 - accuracy: 0.9101 - val_loss: 0.3046 - val_accuracy: 0.8916\n",
      "Epoch 166/2000\n",
      "1/1 [==============================] - 1s 733ms/step - loss: 0.2484 - accuracy: 0.9102 - val_loss: 0.3046 - val_accuracy: 0.8920\n",
      "Epoch 167/2000\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 0.2484 - accuracy: 0.9102 - val_loss: 0.3046 - val_accuracy: 0.8916\n",
      "Epoch 168/2000\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 0.2484 - accuracy: 0.9102 - val_loss: 0.3046 - val_accuracy: 0.8918\n",
      "Epoch 169/2000\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 0.2483 - accuracy: 0.9102 - val_loss: 0.3045 - val_accuracy: 0.8916\n",
      "Epoch 170/2000\n",
      "1/1 [==============================] - 1s 732ms/step - loss: 0.2483 - accuracy: 0.9103 - val_loss: 0.3046 - val_accuracy: 0.8918\n",
      "Epoch 171/2000\n",
      "1/1 [==============================] - 1s 731ms/step - loss: 0.2482 - accuracy: 0.9103 - val_loss: 0.3045 - val_accuracy: 0.8916\n",
      "Epoch 172/2000\n",
      "1/1 [==============================] - 1s 733ms/step - loss: 0.2482 - accuracy: 0.9103 - val_loss: 0.3045 - val_accuracy: 0.8918\n",
      "Epoch 173/2000\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 0.2482 - accuracy: 0.9103 - val_loss: 0.3045 - val_accuracy: 0.8918\n",
      "Epoch 174/2000\n",
      "1/1 [==============================] - 1s 732ms/step - loss: 0.2481 - accuracy: 0.9103 - val_loss: 0.3045 - val_accuracy: 0.8918\n",
      "Epoch 175/2000\n",
      "1/1 [==============================] - 1s 733ms/step - loss: 0.2481 - accuracy: 0.9103 - val_loss: 0.3045 - val_accuracy: 0.8918\n",
      "Epoch 176/2000\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 0.2481 - accuracy: 0.9103 - val_loss: 0.3045 - val_accuracy: 0.8918\n",
      "Epoch 177/2000\n",
      "1/1 [==============================] - 1s 735ms/step - loss: 0.2480 - accuracy: 0.9103 - val_loss: 0.3045 - val_accuracy: 0.8918\n",
      "Epoch 178/2000\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 0.2480 - accuracy: 0.9103 - val_loss: 0.3045 - val_accuracy: 0.8918\n",
      "Epoch 179/2000\n",
      "1/1 [==============================] - 1s 733ms/step - loss: 0.2480 - accuracy: 0.9103 - val_loss: 0.3044 - val_accuracy: 0.8918\n",
      "Epoch 180/2000\n",
      "1/1 [==============================] - 1s 714ms/step - loss: 0.2479 - accuracy: 0.9104 - val_loss: 0.3045 - val_accuracy: 0.8918\n",
      "Epoch 181/2000\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 0.2479 - accuracy: 0.9103 - val_loss: 0.3044 - val_accuracy: 0.8920\n",
      "Epoch 182/2000\n",
      "1/1 [==============================] - 1s 734ms/step - loss: 0.2479 - accuracy: 0.9104 - val_loss: 0.3044 - val_accuracy: 0.8918\n",
      "Epoch 183/2000\n",
      "1/1 [==============================] - 1s 732ms/step - loss: 0.2478 - accuracy: 0.9104 - val_loss: 0.3044 - val_accuracy: 0.8920\n",
      "Epoch 184/2000\n",
      "1/1 [==============================] - 1s 716ms/step - loss: 0.2478 - accuracy: 0.9105 - val_loss: 0.3044 - val_accuracy: 0.8916\n",
      "Epoch 185/2000\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 0.2478 - accuracy: 0.9104 - val_loss: 0.3044 - val_accuracy: 0.8920\n",
      "Epoch 186/2000\n",
      "1/1 [==============================] - 1s 730ms/step - loss: 0.2477 - accuracy: 0.9105 - val_loss: 0.3044 - val_accuracy: 0.8918\n",
      "Epoch 187/2000\n",
      "1/1 [==============================] - 1s 732ms/step - loss: 0.2477 - accuracy: 0.9104 - val_loss: 0.3044 - val_accuracy: 0.8916\n",
      "Epoch 188/2000\n",
      "1/1 [==============================] - 1s 733ms/step - loss: 0.2477 - accuracy: 0.9105 - val_loss: 0.3044 - val_accuracy: 0.8918\n",
      "Epoch 189/2000\n",
      "1/1 [==============================] - 1s 719ms/step - loss: 0.2476 - accuracy: 0.9105 - val_loss: 0.3044 - val_accuracy: 0.8916\n",
      "Epoch 190/2000\n",
      "1/1 [==============================] - 1s 734ms/step - loss: 0.2476 - accuracy: 0.9105 - val_loss: 0.3044 - val_accuracy: 0.8920\n",
      "Epoch 191/2000\n",
      "1/1 [==============================] - 1s 732ms/step - loss: 0.2476 - accuracy: 0.9105 - val_loss: 0.3043 - val_accuracy: 0.8916\n",
      "Epoch 192/2000\n",
      "1/1 [==============================] - 1s 732ms/step - loss: 0.2475 - accuracy: 0.9105 - val_loss: 0.3044 - val_accuracy: 0.8920\n",
      "Epoch 193/2000\n",
      "1/1 [==============================] - 1s 734ms/step - loss: 0.2475 - accuracy: 0.9105 - val_loss: 0.3043 - val_accuracy: 0.8916\n",
      "Epoch 194/2000\n",
      "1/1 [==============================] - 1s 749ms/step - loss: 0.2475 - accuracy: 0.9106 - val_loss: 0.3043 - val_accuracy: 0.8920\n",
      "Epoch 195/2000\n",
      "1/1 [==============================] - 1s 732ms/step - loss: 0.2474 - accuracy: 0.9106 - val_loss: 0.3043 - val_accuracy: 0.8916\n",
      "Epoch 196/2000\n",
      "1/1 [==============================] - 1s 736ms/step - loss: 0.2474 - accuracy: 0.9106 - val_loss: 0.3043 - val_accuracy: 0.8920\n",
      "Epoch 197/2000\n",
      "1/1 [==============================] - 1s 731ms/step - loss: 0.2474 - accuracy: 0.9106 - val_loss: 0.3043 - val_accuracy: 0.8916\n",
      "Epoch 198/2000\n",
      "1/1 [==============================] - 1s 750ms/step - loss: 0.2473 - accuracy: 0.9107 - val_loss: 0.3043 - val_accuracy: 0.8920\n",
      "Epoch 199/2000\n",
      "1/1 [==============================] - 1s 768ms/step - loss: 0.2473 - accuracy: 0.9107 - val_loss: 0.3043 - val_accuracy: 0.8916\n",
      "Epoch 200/2000\n",
      "1/1 [==============================] - 1s 747ms/step - loss: 0.2473 - accuracy: 0.9107 - val_loss: 0.3043 - val_accuracy: 0.8920\n",
      "Epoch 201/2000\n",
      "1/1 [==============================] - 1s 733ms/step - loss: 0.2472 - accuracy: 0.9107 - val_loss: 0.3043 - val_accuracy: 0.8916\n",
      "Epoch 202/2000\n",
      "1/1 [==============================] - 1s 733ms/step - loss: 0.2472 - accuracy: 0.9107 - val_loss: 0.3043 - val_accuracy: 0.8920\n",
      "Epoch 203/2000\n",
      "1/1 [==============================] - 1s 732ms/step - loss: 0.2472 - accuracy: 0.9107 - val_loss: 0.3042 - val_accuracy: 0.8916\n",
      "Epoch 204/2000\n",
      "1/1 [==============================] - 1s 748ms/step - loss: 0.2471 - accuracy: 0.9108 - val_loss: 0.3042 - val_accuracy: 0.8918\n",
      "Epoch 205/2000\n",
      "1/1 [==============================] - 1s 750ms/step - loss: 0.2471 - accuracy: 0.9108 - val_loss: 0.3042 - val_accuracy: 0.8916\n",
      "Epoch 206/2000\n",
      "1/1 [==============================] - 1s 733ms/step - loss: 0.2471 - accuracy: 0.9108 - val_loss: 0.3042 - val_accuracy: 0.8918\n",
      "Epoch 207/2000\n",
      "1/1 [==============================] - 1s 739ms/step - loss: 0.2470 - accuracy: 0.9108 - val_loss: 0.3042 - val_accuracy: 0.8918\n",
      "Epoch 208/2000\n",
      "1/1 [==============================] - 1s 733ms/step - loss: 0.2470 - accuracy: 0.9109 - val_loss: 0.3042 - val_accuracy: 0.8918\n",
      "Epoch 209/2000\n",
      "1/1 [==============================] - 1s 750ms/step - loss: 0.2470 - accuracy: 0.9108 - val_loss: 0.3042 - val_accuracy: 0.8920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210/2000\n",
      "1/1 [==============================] - 1s 749ms/step - loss: 0.2469 - accuracy: 0.9109 - val_loss: 0.3042 - val_accuracy: 0.8920\n",
      "Epoch 211/2000\n",
      "1/1 [==============================] - 1s 748ms/step - loss: 0.2469 - accuracy: 0.9108 - val_loss: 0.3042 - val_accuracy: 0.8922\n",
      "Epoch 212/2000\n",
      "1/1 [==============================] - 1s 748ms/step - loss: 0.2469 - accuracy: 0.9109 - val_loss: 0.3042 - val_accuracy: 0.8920\n",
      "Epoch 213/2000\n",
      "1/1 [==============================] - 1s 765ms/step - loss: 0.2468 - accuracy: 0.9109 - val_loss: 0.3042 - val_accuracy: 0.8924\n",
      "Epoch 214/2000\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.2468 - accuracy: 0.9109 - val_loss: 0.3042 - val_accuracy: 0.8920\n",
      "Epoch 215/2000\n",
      "1/1 [==============================] - 1s 765ms/step - loss: 0.2468 - accuracy: 0.9109 - val_loss: 0.3041 - val_accuracy: 0.8924\n",
      "Epoch 216/2000\n",
      "1/1 [==============================] - 1s 751ms/step - loss: 0.2467 - accuracy: 0.9110 - val_loss: 0.3041 - val_accuracy: 0.8920\n",
      "Epoch 217/2000\n",
      "1/1 [==============================] - 1s 763ms/step - loss: 0.2467 - accuracy: 0.9109 - val_loss: 0.3041 - val_accuracy: 0.8924\n",
      "Epoch 218/2000\n",
      "1/1 [==============================] - 1s 733ms/step - loss: 0.2467 - accuracy: 0.9110 - val_loss: 0.3041 - val_accuracy: 0.8920\n",
      "Epoch 219/2000\n",
      "1/1 [==============================] - 1s 734ms/step - loss: 0.2466 - accuracy: 0.9109 - val_loss: 0.3041 - val_accuracy: 0.8924\n",
      "Epoch 220/2000\n",
      "1/1 [==============================] - 1s 750ms/step - loss: 0.2466 - accuracy: 0.9110 - val_loss: 0.3041 - val_accuracy: 0.8920\n",
      "Epoch 221/2000\n",
      "1/1 [==============================] - 1s 748ms/step - loss: 0.2466 - accuracy: 0.9109 - val_loss: 0.3041 - val_accuracy: 0.8922\n",
      "Epoch 222/2000\n",
      "1/1 [==============================] - 1s 749ms/step - loss: 0.2465 - accuracy: 0.9110 - val_loss: 0.3041 - val_accuracy: 0.8920\n",
      "Epoch 223/2000\n",
      "1/1 [==============================] - 1s 748ms/step - loss: 0.2465 - accuracy: 0.9109 - val_loss: 0.3041 - val_accuracy: 0.8922\n",
      "Epoch 224/2000\n",
      "1/1 [==============================] - 1s 751ms/step - loss: 0.2465 - accuracy: 0.9111 - val_loss: 0.3041 - val_accuracy: 0.8920\n",
      "Epoch 225/2000\n",
      "1/1 [==============================] - 1s 741ms/step - loss: 0.2464 - accuracy: 0.9109 - val_loss: 0.3040 - val_accuracy: 0.8922\n",
      "Epoch 226/2000\n",
      "1/1 [==============================] - 1s 765ms/step - loss: 0.2464 - accuracy: 0.9111 - val_loss: 0.3041 - val_accuracy: 0.8920\n",
      "Epoch 227/2000\n",
      "1/1 [==============================] - 1s 768ms/step - loss: 0.2464 - accuracy: 0.9110 - val_loss: 0.3040 - val_accuracy: 0.8922\n",
      "Epoch 228/2000\n",
      "1/1 [==============================] - 1s 767ms/step - loss: 0.2463 - accuracy: 0.9111 - val_loss: 0.3040 - val_accuracy: 0.8920\n",
      "Epoch 229/2000\n",
      "1/1 [==============================] - 1s 766ms/step - loss: 0.2463 - accuracy: 0.9110 - val_loss: 0.3040 - val_accuracy: 0.8922\n",
      "Epoch 230/2000\n",
      "1/1 [==============================] - 1s 750ms/step - loss: 0.2463 - accuracy: 0.9111 - val_loss: 0.3040 - val_accuracy: 0.8920\n",
      "Epoch 231/2000\n",
      "1/1 [==============================] - 1s 766ms/step - loss: 0.2462 - accuracy: 0.9111 - val_loss: 0.3040 - val_accuracy: 0.8922\n",
      "Epoch 232/2000\n",
      "1/1 [==============================] - 1s 778ms/step - loss: 0.2462 - accuracy: 0.9111 - val_loss: 0.3040 - val_accuracy: 0.8920\n",
      "Epoch 233/2000\n",
      "1/1 [==============================] - 1s 770ms/step - loss: 0.2462 - accuracy: 0.9111 - val_loss: 0.3040 - val_accuracy: 0.8922\n",
      "Epoch 234/2000\n",
      "1/1 [==============================] - 1s 749ms/step - loss: 0.2461 - accuracy: 0.9111 - val_loss: 0.3040 - val_accuracy: 0.8920\n",
      "Epoch 235/2000\n",
      "1/1 [==============================] - 1s 767ms/step - loss: 0.2461 - accuracy: 0.9111 - val_loss: 0.3040 - val_accuracy: 0.8922\n",
      "Epoch 236/2000\n",
      "1/1 [==============================] - 1s 748ms/step - loss: 0.2461 - accuracy: 0.9111 - val_loss: 0.3040 - val_accuracy: 0.8920\n",
      "Epoch 237/2000\n",
      "1/1 [==============================] - 1s 752ms/step - loss: 0.2460 - accuracy: 0.9111 - val_loss: 0.3039 - val_accuracy: 0.8922\n",
      "Epoch 238/2000\n",
      "1/1 [==============================] - 1s 765ms/step - loss: 0.2460 - accuracy: 0.9111 - val_loss: 0.3040 - val_accuracy: 0.8920\n",
      "Epoch 239/2000\n",
      "1/1 [==============================] - 1s 767ms/step - loss: 0.2460 - accuracy: 0.9112 - val_loss: 0.3039 - val_accuracy: 0.8922\n",
      "Epoch 240/2000\n",
      "1/1 [==============================] - 1s 767ms/step - loss: 0.2459 - accuracy: 0.9111 - val_loss: 0.3039 - val_accuracy: 0.8922\n",
      "Epoch 241/2000\n",
      "1/1 [==============================] - 1s 763ms/step - loss: 0.2459 - accuracy: 0.9112 - val_loss: 0.3039 - val_accuracy: 0.8924\n",
      "Epoch 242/2000\n",
      "1/1 [==============================] - 1s 751ms/step - loss: 0.2459 - accuracy: 0.9112 - val_loss: 0.3039 - val_accuracy: 0.8922\n",
      "Epoch 243/2000\n",
      "1/1 [==============================] - 1s 765ms/step - loss: 0.2458 - accuracy: 0.9112 - val_loss: 0.3039 - val_accuracy: 0.8922\n",
      "Epoch 244/2000\n",
      "1/1 [==============================] - 1s 750ms/step - loss: 0.2458 - accuracy: 0.9112 - val_loss: 0.3039 - val_accuracy: 0.8922\n",
      "Epoch 245/2000\n",
      "1/1 [==============================] - 1s 748ms/step - loss: 0.2458 - accuracy: 0.9113 - val_loss: 0.3039 - val_accuracy: 0.8922\n",
      "Epoch 246/2000\n",
      "1/1 [==============================] - 1s 752ms/step - loss: 0.2457 - accuracy: 0.9112 - val_loss: 0.3039 - val_accuracy: 0.8922\n",
      "Epoch 247/2000\n",
      "1/1 [==============================] - 1s 831ms/step - loss: 0.2457 - accuracy: 0.9113 - val_loss: 0.3038 - val_accuracy: 0.8924\n",
      "Epoch 248/2000\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.2457 - accuracy: 0.9112 - val_loss: 0.3039 - val_accuracy: 0.8922\n",
      "Epoch 249/2000\n",
      "1/1 [==============================] - 1s 832ms/step - loss: 0.2456 - accuracy: 0.9114 - val_loss: 0.3038 - val_accuracy: 0.8924\n",
      "Epoch 250/2000\n",
      "1/1 [==============================] - 1s 799ms/step - loss: 0.2456 - accuracy: 0.9112 - val_loss: 0.3038 - val_accuracy: 0.8922\n",
      "Epoch 251/2000\n",
      "1/1 [==============================] - 1s 866ms/step - loss: 0.2456 - accuracy: 0.9114 - val_loss: 0.3038 - val_accuracy: 0.8922\n",
      "Epoch 252/2000\n",
      "1/1 [==============================] - 1s 785ms/step - loss: 0.2455 - accuracy: 0.9113 - val_loss: 0.3038 - val_accuracy: 0.8920\n",
      "Epoch 253/2000\n",
      "1/1 [==============================] - 1s 815ms/step - loss: 0.2455 - accuracy: 0.9114 - val_loss: 0.3038 - val_accuracy: 0.8922\n",
      "Epoch 254/2000\n",
      "1/1 [==============================] - 1s 804ms/step - loss: 0.2455 - accuracy: 0.9113 - val_loss: 0.3038 - val_accuracy: 0.8920\n",
      "Epoch 255/2000\n",
      "1/1 [==============================] - 1s 772ms/step - loss: 0.2454 - accuracy: 0.9115 - val_loss: 0.3038 - val_accuracy: 0.8922\n",
      "Epoch 256/2000\n",
      "1/1 [==============================] - 1s 783ms/step - loss: 0.2454 - accuracy: 0.9113 - val_loss: 0.3038 - val_accuracy: 0.8920\n",
      "Epoch 257/2000\n",
      "1/1 [==============================] - 1s 765ms/step - loss: 0.2454 - accuracy: 0.9115 - val_loss: 0.3038 - val_accuracy: 0.8922\n",
      "Epoch 258/2000\n",
      "1/1 [==============================] - 1s 770ms/step - loss: 0.2453 - accuracy: 0.9113 - val_loss: 0.3038 - val_accuracy: 0.8918\n",
      "Epoch 259/2000\n",
      "1/1 [==============================] - 1s 768ms/step - loss: 0.2453 - accuracy: 0.9114 - val_loss: 0.3038 - val_accuracy: 0.8922\n",
      "Epoch 260/2000\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 0.2453 - accuracy: 0.9113 - val_loss: 0.3038 - val_accuracy: 0.8918\n",
      "Epoch 261/2000\n",
      "1/1 [==============================] - 1s 799ms/step - loss: 0.2452 - accuracy: 0.9115 - val_loss: 0.3037 - val_accuracy: 0.8922\n",
      "Epoch 262/2000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.2452 - accuracy: 0.9113 - val_loss: 0.3037 - val_accuracy: 0.8918\n",
      "Epoch 263/2000\n",
      "1/1 [==============================] - 1s 798ms/step - loss: 0.2452 - accuracy: 0.9115 - val_loss: 0.3037 - val_accuracy: 0.8922\n",
      "Epoch 264/2000\n",
      "1/1 [==============================] - 1s 800ms/step - loss: 0.2451 - accuracy: 0.9114 - val_loss: 0.3037 - val_accuracy: 0.8918\n",
      "Epoch 265/2000\n",
      "1/1 [==============================] - 1s 799ms/step - loss: 0.2451 - accuracy: 0.9115 - val_loss: 0.3037 - val_accuracy: 0.8922\n",
      "Epoch 266/2000\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.2451 - accuracy: 0.9114 - val_loss: 0.3037 - val_accuracy: 0.8918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 267/2000\n",
      "1/1 [==============================] - 1s 895ms/step - loss: 0.2450 - accuracy: 0.9115 - val_loss: 0.3037 - val_accuracy: 0.8924\n",
      "Epoch 268/2000\n",
      "1/1 [==============================] - 1s 913ms/step - loss: 0.2450 - accuracy: 0.9114 - val_loss: 0.3037 - val_accuracy: 0.8918\n",
      "Epoch 269/2000\n",
      "1/1 [==============================] - 1s 866ms/step - loss: 0.2450 - accuracy: 0.9115 - val_loss: 0.3037 - val_accuracy: 0.8924\n",
      "Epoch 270/2000\n",
      "1/1 [==============================] - 1s 918ms/step - loss: 0.2449 - accuracy: 0.9115 - val_loss: 0.3037 - val_accuracy: 0.8918\n",
      "Epoch 271/2000\n",
      "1/1 [==============================] - 1s 907ms/step - loss: 0.2449 - accuracy: 0.9116 - val_loss: 0.3037 - val_accuracy: 0.8926\n",
      "Epoch 272/2000\n",
      "1/1 [==============================] - 1s 801ms/step - loss: 0.2449 - accuracy: 0.9115 - val_loss: 0.3037 - val_accuracy: 0.8918\n",
      "Epoch 273/2000\n",
      "1/1 [==============================] - 1s 802ms/step - loss: 0.2448 - accuracy: 0.9116 - val_loss: 0.3036 - val_accuracy: 0.8926\n",
      "Epoch 274/2000\n",
      "1/1 [==============================] - 1s 814ms/step - loss: 0.2448 - accuracy: 0.9115 - val_loss: 0.3036 - val_accuracy: 0.8920\n",
      "Epoch 275/2000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.2448 - accuracy: 0.9116 - val_loss: 0.3036 - val_accuracy: 0.8926\n",
      "Epoch 276/2000\n",
      "1/1 [==============================] - 1s 831ms/step - loss: 0.2447 - accuracy: 0.9115 - val_loss: 0.3036 - val_accuracy: 0.8918\n",
      "Epoch 277/2000\n",
      "1/1 [==============================] - 1s 834ms/step - loss: 0.2447 - accuracy: 0.9117 - val_loss: 0.3036 - val_accuracy: 0.8924\n",
      "Epoch 278/2000\n",
      "1/1 [==============================] - 1s 937ms/step - loss: 0.2447 - accuracy: 0.9116 - val_loss: 0.3036 - val_accuracy: 0.8918\n",
      "Epoch 279/2000\n",
      "1/1 [==============================] - 1s 873ms/step - loss: 0.2446 - accuracy: 0.9117 - val_loss: 0.3036 - val_accuracy: 0.8924\n",
      "Epoch 280/2000\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 0.2446 - accuracy: 0.9116 - val_loss: 0.3036 - val_accuracy: 0.8918\n",
      "Epoch 281/2000\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 0.2446 - accuracy: 0.9117 - val_loss: 0.3036 - val_accuracy: 0.8924\n",
      "Epoch 282/2000\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 0.2445 - accuracy: 0.9116 - val_loss: 0.3036 - val_accuracy: 0.8918\n",
      "Epoch 283/2000\n",
      "1/1 [==============================] - 1s 914ms/step - loss: 0.2445 - accuracy: 0.9117 - val_loss: 0.3036 - val_accuracy: 0.8924\n",
      "Epoch 284/2000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.2445 - accuracy: 0.9117 - val_loss: 0.3035 - val_accuracy: 0.8918\n",
      "Epoch 285/2000\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 0.2444 - accuracy: 0.9118 - val_loss: 0.3035 - val_accuracy: 0.8924\n",
      "Epoch 286/2000\n",
      "1/1 [==============================] - 1s 829ms/step - loss: 0.2444 - accuracy: 0.9117 - val_loss: 0.3035 - val_accuracy: 0.8918\n",
      "Epoch 287/2000\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.2444 - accuracy: 0.9118 - val_loss: 0.3035 - val_accuracy: 0.8922\n",
      "Epoch 288/2000\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.2443 - accuracy: 0.9117 - val_loss: 0.3035 - val_accuracy: 0.8918\n",
      "Epoch 289/2000\n",
      "1/1 [==============================] - 1s 830ms/step - loss: 0.2443 - accuracy: 0.9118 - val_loss: 0.3035 - val_accuracy: 0.8922\n",
      "Epoch 290/2000\n",
      "1/1 [==============================] - 1s 850ms/step - loss: 0.2443 - accuracy: 0.9117 - val_loss: 0.3035 - val_accuracy: 0.8918\n",
      "Epoch 291/2000\n",
      "1/1 [==============================] - 1s 814ms/step - loss: 0.2442 - accuracy: 0.9118 - val_loss: 0.3035 - val_accuracy: 0.8924\n",
      "Epoch 292/2000\n",
      "1/1 [==============================] - 1s 801ms/step - loss: 0.2442 - accuracy: 0.9118 - val_loss: 0.3035 - val_accuracy: 0.8918\n",
      "Epoch 293/2000\n",
      "1/1 [==============================] - 1s 800ms/step - loss: 0.2442 - accuracy: 0.9119 - val_loss: 0.3035 - val_accuracy: 0.8924\n",
      "Epoch 294/2000\n",
      "1/1 [==============================] - 1s 801ms/step - loss: 0.2441 - accuracy: 0.9118 - val_loss: 0.3035 - val_accuracy: 0.8918\n",
      "Epoch 295/2000\n",
      "1/1 [==============================] - 1s 813ms/step - loss: 0.2441 - accuracy: 0.9119 - val_loss: 0.3035 - val_accuracy: 0.8924\n",
      "Epoch 296/2000\n",
      "1/1 [==============================] - 1s 831ms/step - loss: 0.2441 - accuracy: 0.9118 - val_loss: 0.3034 - val_accuracy: 0.8920\n",
      "Epoch 297/2000\n",
      "1/1 [==============================] - 1s 802ms/step - loss: 0.2441 - accuracy: 0.9120 - val_loss: 0.3035 - val_accuracy: 0.8924\n",
      "Epoch 298/2000\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 0.2440 - accuracy: 0.9119 - val_loss: 0.3034 - val_accuracy: 0.8920\n",
      "Epoch 299/2000\n",
      "1/1 [==============================] - 1s 800ms/step - loss: 0.2440 - accuracy: 0.9120 - val_loss: 0.3034 - val_accuracy: 0.8924\n",
      "Epoch 300/2000\n",
      "1/1 [==============================] - 1s 802ms/step - loss: 0.2440 - accuracy: 0.9119 - val_loss: 0.3034 - val_accuracy: 0.8922\n",
      "Epoch 301/2000\n",
      "1/1 [==============================] - 1s 833ms/step - loss: 0.2439 - accuracy: 0.9120 - val_loss: 0.3034 - val_accuracy: 0.8924\n",
      "Epoch 302/2000\n",
      "1/1 [==============================] - 1s 815ms/step - loss: 0.2439 - accuracy: 0.9119 - val_loss: 0.3034 - val_accuracy: 0.8922\n",
      "Epoch 303/2000\n",
      "1/1 [==============================] - 1s 799ms/step - loss: 0.2439 - accuracy: 0.9120 - val_loss: 0.3034 - val_accuracy: 0.8924\n",
      "Epoch 304/2000\n",
      "1/1 [==============================] - 1s 815ms/step - loss: 0.2438 - accuracy: 0.9119 - val_loss: 0.3034 - val_accuracy: 0.8922\n",
      "Epoch 305/2000\n",
      "1/1 [==============================] - 1s 832ms/step - loss: 0.2438 - accuracy: 0.9121 - val_loss: 0.3034 - val_accuracy: 0.8924\n",
      "Epoch 306/2000\n",
      "1/1 [==============================] - 1s 801ms/step - loss: 0.2438 - accuracy: 0.9120 - val_loss: 0.3034 - val_accuracy: 0.8922\n",
      "Epoch 307/2000\n",
      "1/1 [==============================] - 1s 814ms/step - loss: 0.2437 - accuracy: 0.9121 - val_loss: 0.3034 - val_accuracy: 0.8924\n",
      "Epoch 308/2000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.2437 - accuracy: 0.9120 - val_loss: 0.3034 - val_accuracy: 0.8924\n",
      "Epoch 309/2000\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.2437 - accuracy: 0.9121 - val_loss: 0.3033 - val_accuracy: 0.8924\n",
      "Epoch 310/2000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.2436 - accuracy: 0.9120 - val_loss: 0.3033 - val_accuracy: 0.8924\n",
      "Epoch 311/2000\n",
      "1/1 [==============================] - 1s 813ms/step - loss: 0.2436 - accuracy: 0.9121 - val_loss: 0.3033 - val_accuracy: 0.8926\n",
      "Epoch 312/2000\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 0.2436 - accuracy: 0.9121 - val_loss: 0.3033 - val_accuracy: 0.8924\n",
      "Epoch 313/2000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.2435 - accuracy: 0.9122 - val_loss: 0.3033 - val_accuracy: 0.8926\n",
      "Epoch 314/2000\n",
      "1/1 [==============================] - 1s 832ms/step - loss: 0.2435 - accuracy: 0.9121 - val_loss: 0.3033 - val_accuracy: 0.8924\n",
      "Epoch 315/2000\n",
      "1/1 [==============================] - 1s 815ms/step - loss: 0.2435 - accuracy: 0.9123 - val_loss: 0.3033 - val_accuracy: 0.8926\n",
      "Epoch 316/2000\n",
      "1/1 [==============================] - 1s 814ms/step - loss: 0.2434 - accuracy: 0.9121 - val_loss: 0.3033 - val_accuracy: 0.8924\n",
      "Epoch 317/2000\n",
      "1/1 [==============================] - 1s 804ms/step - loss: 0.2434 - accuracy: 0.9123 - val_loss: 0.3033 - val_accuracy: 0.8926\n",
      "Epoch 318/2000\n",
      "1/1 [==============================] - 1s 800ms/step - loss: 0.2434 - accuracy: 0.9121 - val_loss: 0.3033 - val_accuracy: 0.8924\n",
      "Epoch 319/2000\n",
      "1/1 [==============================] - 1s 815ms/step - loss: 0.2433 - accuracy: 0.9123 - val_loss: 0.3033 - val_accuracy: 0.8928\n",
      "Epoch 320/2000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.2433 - accuracy: 0.9122 - val_loss: 0.3032 - val_accuracy: 0.8924\n",
      "Epoch 321/2000\n",
      "1/1 [==============================] - 1s 847ms/step - loss: 0.2433 - accuracy: 0.9123 - val_loss: 0.3032 - val_accuracy: 0.8930\n",
      "Epoch 322/2000\n",
      "1/1 [==============================] - 1s 833ms/step - loss: 0.2432 - accuracy: 0.9122 - val_loss: 0.3032 - val_accuracy: 0.8922\n",
      "Epoch 323/2000\n",
      "1/1 [==============================] - 1s 829ms/step - loss: 0.2432 - accuracy: 0.9123 - val_loss: 0.3032 - val_accuracy: 0.8930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 324/2000\n",
      "1/1 [==============================] - 1s 836ms/step - loss: 0.2432 - accuracy: 0.9122 - val_loss: 0.3032 - val_accuracy: 0.8922\n",
      "Epoch 325/2000\n",
      "1/1 [==============================] - 1s 835ms/step - loss: 0.2431 - accuracy: 0.9123 - val_loss: 0.3032 - val_accuracy: 0.8932\n",
      "Epoch 326/2000\n",
      "1/1 [==============================] - 1s 848ms/step - loss: 0.2431 - accuracy: 0.9122 - val_loss: 0.3032 - val_accuracy: 0.8922\n",
      "Epoch 327/2000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.2431 - accuracy: 0.9124 - val_loss: 0.3032 - val_accuracy: 0.8932\n",
      "Epoch 328/2000\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.2430 - accuracy: 0.9123 - val_loss: 0.3032 - val_accuracy: 0.8922\n",
      "Epoch 329/2000\n",
      "1/1 [==============================] - 1s 835ms/step - loss: 0.2430 - accuracy: 0.9124 - val_loss: 0.3032 - val_accuracy: 0.8932\n",
      "Epoch 330/2000\n",
      "1/1 [==============================] - 1s 828ms/step - loss: 0.2430 - accuracy: 0.9123 - val_loss: 0.3032 - val_accuracy: 0.8922\n",
      "Epoch 331/2000\n",
      "1/1 [==============================] - 1s 835ms/step - loss: 0.2429 - accuracy: 0.9124 - val_loss: 0.3032 - val_accuracy: 0.8932\n",
      "Epoch 332/2000\n",
      "1/1 [==============================] - 1s 832ms/step - loss: 0.2429 - accuracy: 0.9123 - val_loss: 0.3031 - val_accuracy: 0.8922\n",
      "Epoch 333/2000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.2429 - accuracy: 0.9125 - val_loss: 0.3032 - val_accuracy: 0.8932\n",
      "Epoch 334/2000\n",
      "1/1 [==============================] - 1s 832ms/step - loss: 0.2428 - accuracy: 0.9123 - val_loss: 0.3031 - val_accuracy: 0.8924\n",
      "Epoch 335/2000\n",
      "1/1 [==============================] - 1s 831ms/step - loss: 0.2428 - accuracy: 0.9125 - val_loss: 0.3031 - val_accuracy: 0.8932\n",
      "Epoch 336/2000\n",
      "1/1 [==============================] - 1s 834ms/step - loss: 0.2428 - accuracy: 0.9123 - val_loss: 0.3031 - val_accuracy: 0.8924\n",
      "Epoch 337/2000\n",
      "1/1 [==============================] - 1s 829ms/step - loss: 0.2427 - accuracy: 0.9125 - val_loss: 0.3031 - val_accuracy: 0.8932\n",
      "Epoch 338/2000\n",
      "1/1 [==============================] - 1s 852ms/step - loss: 0.2427 - accuracy: 0.9124 - val_loss: 0.3031 - val_accuracy: 0.8924\n",
      "Epoch 339/2000\n",
      "1/1 [==============================] - 1s 833ms/step - loss: 0.2427 - accuracy: 0.9124 - val_loss: 0.3031 - val_accuracy: 0.8932\n",
      "Epoch 340/2000\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 0.2426 - accuracy: 0.9125 - val_loss: 0.3031 - val_accuracy: 0.8924\n",
      "Epoch 341/2000\n",
      "1/1 [==============================] - 1s 847ms/step - loss: 0.2426 - accuracy: 0.9124 - val_loss: 0.3031 - val_accuracy: 0.8932\n",
      "Epoch 342/2000\n",
      "1/1 [==============================] - 1s 851ms/step - loss: 0.2426 - accuracy: 0.9125 - val_loss: 0.3031 - val_accuracy: 0.8924\n",
      "Epoch 343/2000\n",
      "1/1 [==============================] - 1s 863ms/step - loss: 0.2425 - accuracy: 0.9125 - val_loss: 0.3031 - val_accuracy: 0.8932\n",
      "Epoch 344/2000\n",
      "1/1 [==============================] - 1s 851ms/step - loss: 0.2425 - accuracy: 0.9125 - val_loss: 0.3031 - val_accuracy: 0.8924\n",
      "Epoch 345/2000\n",
      "1/1 [==============================] - 1s 834ms/step - loss: 0.2425 - accuracy: 0.9125 - val_loss: 0.3031 - val_accuracy: 0.8932\n",
      "Epoch 346/2000\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.2424 - accuracy: 0.9125 - val_loss: 0.3030 - val_accuracy: 0.8924\n",
      "Epoch 347/2000\n",
      "1/1 [==============================] - 1s 835ms/step - loss: 0.2424 - accuracy: 0.9125 - val_loss: 0.3030 - val_accuracy: 0.8932\n",
      "Epoch 348/2000\n",
      "1/1 [==============================] - 1s 833ms/step - loss: 0.2424 - accuracy: 0.9125 - val_loss: 0.3030 - val_accuracy: 0.8922\n",
      "Epoch 349/2000\n",
      "1/1 [==============================] - 1s 867ms/step - loss: 0.2423 - accuracy: 0.9125 - val_loss: 0.3030 - val_accuracy: 0.8932\n",
      "Epoch 350/2000\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 0.2423 - accuracy: 0.9125 - val_loss: 0.3030 - val_accuracy: 0.8922\n",
      "Epoch 351/2000\n",
      "1/1 [==============================] - 1s 834ms/step - loss: 0.2423 - accuracy: 0.9126 - val_loss: 0.3030 - val_accuracy: 0.8932\n",
      "Epoch 352/2000\n",
      "1/1 [==============================] - 1s 848ms/step - loss: 0.2422 - accuracy: 0.9125 - val_loss: 0.3030 - val_accuracy: 0.8922\n",
      "Epoch 353/2000\n",
      "1/1 [==============================] - 1s 850ms/step - loss: 0.2422 - accuracy: 0.9126 - val_loss: 0.3030 - val_accuracy: 0.8930\n",
      "Epoch 354/2000\n",
      "1/1 [==============================] - 1s 833ms/step - loss: 0.2422 - accuracy: 0.9125 - val_loss: 0.3030 - val_accuracy: 0.8922\n",
      "Epoch 355/2000\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 0.2422 - accuracy: 0.9126 - val_loss: 0.3030 - val_accuracy: 0.8930\n",
      "Epoch 356/2000\n",
      "1/1 [==============================] - 1s 866ms/step - loss: 0.2421 - accuracy: 0.9126 - val_loss: 0.3030 - val_accuracy: 0.8922\n",
      "Epoch 357/2000\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.2421 - accuracy: 0.9126 - val_loss: 0.3030 - val_accuracy: 0.8930\n",
      "Epoch 358/2000\n",
      "1/1 [==============================] - 1s 867ms/step - loss: 0.2421 - accuracy: 0.9127 - val_loss: 0.3029 - val_accuracy: 0.8922\n",
      "Epoch 359/2000\n",
      "1/1 [==============================] - 1s 867ms/step - loss: 0.2420 - accuracy: 0.9126 - val_loss: 0.3030 - val_accuracy: 0.8930\n",
      "Epoch 360/2000\n",
      "1/1 [==============================] - 1s 891ms/step - loss: 0.2420 - accuracy: 0.9127 - val_loss: 0.3029 - val_accuracy: 0.8924\n",
      "Epoch 361/2000\n",
      "1/1 [==============================] - 1s 923ms/step - loss: 0.2420 - accuracy: 0.9127 - val_loss: 0.3029 - val_accuracy: 0.8930\n",
      "Epoch 362/2000\n",
      "1/1 [==============================] - 1s 867ms/step - loss: 0.2419 - accuracy: 0.9127 - val_loss: 0.3029 - val_accuracy: 0.8926\n",
      "Epoch 363/2000\n",
      "1/1 [==============================] - 1s 880ms/step - loss: 0.2419 - accuracy: 0.9127 - val_loss: 0.3029 - val_accuracy: 0.8930\n",
      "Epoch 364/2000\n",
      "1/1 [==============================] - 1s 868ms/step - loss: 0.2419 - accuracy: 0.9127 - val_loss: 0.3029 - val_accuracy: 0.8926\n",
      "Epoch 365/2000\n",
      "1/1 [==============================] - 1s 866ms/step - loss: 0.2418 - accuracy: 0.9127 - val_loss: 0.3029 - val_accuracy: 0.8930\n",
      "Epoch 366/2000\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.2418 - accuracy: 0.9128 - val_loss: 0.3029 - val_accuracy: 0.8924\n",
      "Epoch 367/2000\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.2418 - accuracy: 0.9127 - val_loss: 0.3029 - val_accuracy: 0.8932\n",
      "Epoch 368/2000\n",
      "1/1 [==============================] - 1s 872ms/step - loss: 0.2417 - accuracy: 0.9128 - val_loss: 0.3029 - val_accuracy: 0.8924\n",
      "Epoch 369/2000\n",
      "1/1 [==============================] - 1s 857ms/step - loss: 0.2417 - accuracy: 0.9127 - val_loss: 0.3029 - val_accuracy: 0.8934\n",
      "Epoch 370/2000\n",
      "1/1 [==============================] - 1s 850ms/step - loss: 0.2417 - accuracy: 0.9128 - val_loss: 0.3029 - val_accuracy: 0.8926\n",
      "Epoch 371/2000\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 0.2416 - accuracy: 0.9127 - val_loss: 0.3028 - val_accuracy: 0.8934\n",
      "Epoch 372/2000\n",
      "1/1 [==============================] - 1s 884ms/step - loss: 0.2416 - accuracy: 0.9128 - val_loss: 0.3029 - val_accuracy: 0.8926\n",
      "Epoch 373/2000\n",
      "1/1 [==============================] - 1s 897ms/step - loss: 0.2416 - accuracy: 0.9128 - val_loss: 0.3028 - val_accuracy: 0.8934\n",
      "Epoch 374/2000\n",
      "1/1 [==============================] - 1s 884ms/step - loss: 0.2415 - accuracy: 0.9129 - val_loss: 0.3028 - val_accuracy: 0.8926\n",
      "Epoch 375/2000\n",
      "1/1 [==============================] - 1s 868ms/step - loss: 0.2415 - accuracy: 0.9128 - val_loss: 0.3028 - val_accuracy: 0.8934\n",
      "Epoch 376/2000\n",
      "1/1 [==============================] - 1s 882ms/step - loss: 0.2415 - accuracy: 0.9129 - val_loss: 0.3028 - val_accuracy: 0.8926\n",
      "Epoch 377/2000\n",
      "1/1 [==============================] - 1s 888ms/step - loss: 0.2414 - accuracy: 0.9129 - val_loss: 0.3028 - val_accuracy: 0.8934\n",
      "Epoch 378/2000\n",
      "1/1 [==============================] - 1s 879ms/step - loss: 0.2414 - accuracy: 0.9129 - val_loss: 0.3028 - val_accuracy: 0.8926\n",
      "Epoch 379/2000\n",
      "1/1 [==============================] - 1s 882ms/step - loss: 0.2414 - accuracy: 0.9129 - val_loss: 0.3028 - val_accuracy: 0.8934\n",
      "Epoch 380/2000\n",
      "1/1 [==============================] - 1s 881ms/step - loss: 0.2413 - accuracy: 0.9129 - val_loss: 0.3028 - val_accuracy: 0.8926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/2000\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 0.2413 - accuracy: 0.9129 - val_loss: 0.3028 - val_accuracy: 0.8932\n",
      "Epoch 382/2000\n",
      "1/1 [==============================] - 1s 899ms/step - loss: 0.2413 - accuracy: 0.9129 - val_loss: 0.3028 - val_accuracy: 0.8926\n",
      "Epoch 383/2000\n",
      "1/1 [==============================] - 1s 885ms/step - loss: 0.2412 - accuracy: 0.9129 - val_loss: 0.3028 - val_accuracy: 0.8932\n",
      "Epoch 384/2000\n",
      "1/1 [==============================] - 1s 882ms/step - loss: 0.2412 - accuracy: 0.9130 - val_loss: 0.3028 - val_accuracy: 0.8926\n",
      "Epoch 385/2000\n",
      "1/1 [==============================] - 1s 876ms/step - loss: 0.2412 - accuracy: 0.9130 - val_loss: 0.3028 - val_accuracy: 0.8932\n",
      "Epoch 386/2000\n",
      "1/1 [==============================] - 1s 897ms/step - loss: 0.2411 - accuracy: 0.9130 - val_loss: 0.3028 - val_accuracy: 0.8926\n",
      "Epoch 387/2000\n",
      "1/1 [==============================] - 1s 868ms/step - loss: 0.2411 - accuracy: 0.9130 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 388/2000\n",
      "1/1 [==============================] - 1s 883ms/step - loss: 0.2411 - accuracy: 0.9130 - val_loss: 0.3027 - val_accuracy: 0.8926\n",
      "Epoch 389/2000\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 0.2410 - accuracy: 0.9131 - val_loss: 0.3027 - val_accuracy: 0.8930\n",
      "Epoch 390/2000\n",
      "1/1 [==============================] - 1s 899ms/step - loss: 0.2410 - accuracy: 0.9130 - val_loss: 0.3027 - val_accuracy: 0.8926\n",
      "Epoch 391/2000\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 0.2410 - accuracy: 0.9131 - val_loss: 0.3027 - val_accuracy: 0.8930\n",
      "Epoch 392/2000\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 0.2410 - accuracy: 0.9130 - val_loss: 0.3027 - val_accuracy: 0.8926\n",
      "Epoch 393/2000\n",
      "1/1 [==============================] - 1s 889ms/step - loss: 0.2409 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8928\n",
      "Epoch 394/2000\n",
      "1/1 [==============================] - 1s 900ms/step - loss: 0.2409 - accuracy: 0.9130 - val_loss: 0.3027 - val_accuracy: 0.8926\n",
      "Epoch 395/2000\n",
      "1/1 [==============================] - 1s 886ms/step - loss: 0.2409 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8928\n",
      "Epoch 396/2000\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 0.2408 - accuracy: 0.9131 - val_loss: 0.3027 - val_accuracy: 0.8926\n",
      "Epoch 397/2000\n",
      "1/1 [==============================] - 1s 916ms/step - loss: 0.2408 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8928\n",
      "Epoch 398/2000\n",
      "1/1 [==============================] - 1s 900ms/step - loss: 0.2408 - accuracy: 0.9131 - val_loss: 0.3026 - val_accuracy: 0.8926\n",
      "Epoch 399/2000\n",
      "1/1 [==============================] - 1s 914ms/step - loss: 0.2407 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8928\n",
      "Epoch 400/2000\n",
      "1/1 [==============================] - 1s 917ms/step - loss: 0.2407 - accuracy: 0.9132 - val_loss: 0.3026 - val_accuracy: 0.8928\n",
      "Epoch 401/2000\n",
      "1/1 [==============================] - 1s 883ms/step - loss: 0.2407 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8928\n",
      "Epoch 402/2000\n",
      "1/1 [==============================] - 1s 897ms/step - loss: 0.2406 - accuracy: 0.9131 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 403/2000\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 0.2406 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8928\n",
      "Epoch 404/2000\n",
      "1/1 [==============================] - 1s 900ms/step - loss: 0.2406 - accuracy: 0.9132 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 405/2000\n",
      "1/1 [==============================] - 1s 899ms/step - loss: 0.2405 - accuracy: 0.9134 - val_loss: 0.3026 - val_accuracy: 0.8928\n",
      "Epoch 406/2000\n",
      "1/1 [==============================] - 1s 899ms/step - loss: 0.2405 - accuracy: 0.9132 - val_loss: 0.3026 - val_accuracy: 0.8928\n",
      "Epoch 407/2000\n",
      "1/1 [==============================] - 1s 899ms/step - loss: 0.2405 - accuracy: 0.9134 - val_loss: 0.3026 - val_accuracy: 0.8928\n",
      "Epoch 408/2000\n",
      "1/1 [==============================] - 1s 918ms/step - loss: 0.2404 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 409/2000\n",
      "1/1 [==============================] - 1s 931ms/step - loss: 0.2404 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8928\n",
      "Epoch 410/2000\n",
      "1/1 [==============================] - 1s 918ms/step - loss: 0.2404 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 411/2000\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 0.2403 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8928\n",
      "Epoch 412/2000\n",
      "1/1 [==============================] - 1s 905ms/step - loss: 0.2403 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 413/2000\n",
      "1/1 [==============================] - 1s 925ms/step - loss: 0.2403 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8928\n",
      "Epoch 414/2000\n",
      "1/1 [==============================] - 1s 918ms/step - loss: 0.2402 - accuracy: 0.9134 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 415/2000\n",
      "1/1 [==============================] - 1s 913ms/step - loss: 0.2402 - accuracy: 0.9134 - val_loss: 0.3026 - val_accuracy: 0.8928\n",
      "Epoch 416/2000\n",
      "1/1 [==============================] - 1s 915ms/step - loss: 0.2402 - accuracy: 0.9135 - val_loss: 0.3025 - val_accuracy: 0.8930\n",
      "Epoch 417/2000\n",
      "1/1 [==============================] - 1s 921ms/step - loss: 0.2401 - accuracy: 0.9135 - val_loss: 0.3025 - val_accuracy: 0.8928\n",
      "Epoch 418/2000\n",
      "1/1 [==============================] - 1s 928ms/step - loss: 0.2401 - accuracy: 0.9135 - val_loss: 0.3025 - val_accuracy: 0.8930\n",
      "Epoch 419/2000\n",
      "1/1 [==============================] - 1s 916ms/step - loss: 0.2401 - accuracy: 0.9135 - val_loss: 0.3025 - val_accuracy: 0.8928\n",
      "Epoch 420/2000\n",
      "1/1 [==============================] - 1s 915ms/step - loss: 0.2400 - accuracy: 0.9135 - val_loss: 0.3025 - val_accuracy: 0.8930\n",
      "Epoch 421/2000\n",
      "1/1 [==============================] - 1s 903ms/step - loss: 0.2400 - accuracy: 0.9135 - val_loss: 0.3025 - val_accuracy: 0.8928\n",
      "Epoch 422/2000\n",
      "1/1 [==============================] - 1s 915ms/step - loss: 0.2400 - accuracy: 0.9135 - val_loss: 0.3025 - val_accuracy: 0.8930\n",
      "Epoch 423/2000\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 0.2399 - accuracy: 0.9135 - val_loss: 0.3025 - val_accuracy: 0.8928\n",
      "Epoch 424/2000\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.2399 - accuracy: 0.9135 - val_loss: 0.3025 - val_accuracy: 0.8930\n",
      "Epoch 425/2000\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 0.2399 - accuracy: 0.9136 - val_loss: 0.3025 - val_accuracy: 0.8928\n",
      "Epoch 426/2000\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.2399 - accuracy: 0.9135 - val_loss: 0.3025 - val_accuracy: 0.8930\n",
      "Epoch 427/2000\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.2398 - accuracy: 0.9137 - val_loss: 0.3025 - val_accuracy: 0.8926\n",
      "Epoch 428/2000\n",
      "1/1 [==============================] - 1s 933ms/step - loss: 0.2398 - accuracy: 0.9136 - val_loss: 0.3024 - val_accuracy: 0.8928\n",
      "Epoch 429/2000\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.2398 - accuracy: 0.9137 - val_loss: 0.3025 - val_accuracy: 0.8926\n",
      "Epoch 430/2000\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.2397 - accuracy: 0.9136 - val_loss: 0.3024 - val_accuracy: 0.8928\n",
      "Epoch 431/2000\n",
      "1/1 [==============================] - 1s 947ms/step - loss: 0.2397 - accuracy: 0.9137 - val_loss: 0.3024 - val_accuracy: 0.8926\n",
      "Epoch 432/2000\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 0.2397 - accuracy: 0.9136 - val_loss: 0.3024 - val_accuracy: 0.8928\n",
      "Epoch 433/2000\n",
      "1/1 [==============================] - 1s 965ms/step - loss: 0.2396 - accuracy: 0.9137 - val_loss: 0.3024 - val_accuracy: 0.8926\n",
      "Epoch 434/2000\n",
      "1/1 [==============================] - 1s 976ms/step - loss: 0.2396 - accuracy: 0.9136 - val_loss: 0.3024 - val_accuracy: 0.8928\n",
      "Epoch 435/2000\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.2396 - accuracy: 0.9137 - val_loss: 0.3024 - val_accuracy: 0.8926\n",
      "Epoch 436/2000\n",
      "1/1 [==============================] - 1s 970ms/step - loss: 0.2395 - accuracy: 0.9136 - val_loss: 0.3024 - val_accuracy: 0.8928\n",
      "Epoch 437/2000\n",
      "1/1 [==============================] - 1s 946ms/step - loss: 0.2395 - accuracy: 0.9138 - val_loss: 0.3024 - val_accuracy: 0.8926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 438/2000\n",
      "1/1 [==============================] - 1s 966ms/step - loss: 0.2395 - accuracy: 0.9137 - val_loss: 0.3024 - val_accuracy: 0.8928\n",
      "Epoch 439/2000\n",
      "1/1 [==============================] - 1s 946ms/step - loss: 0.2394 - accuracy: 0.9138 - val_loss: 0.3024 - val_accuracy: 0.8926\n",
      "Epoch 440/2000\n",
      "1/1 [==============================] - 1s 933ms/step - loss: 0.2394 - accuracy: 0.9137 - val_loss: 0.3024 - val_accuracy: 0.8930\n",
      "Epoch 441/2000\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 0.2394 - accuracy: 0.9138 - val_loss: 0.3024 - val_accuracy: 0.8926\n",
      "Epoch 442/2000\n",
      "1/1 [==============================] - 1s 952ms/step - loss: 0.2393 - accuracy: 0.9137 - val_loss: 0.3023 - val_accuracy: 0.8930\n",
      "Epoch 443/2000\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 0.2393 - accuracy: 0.9139 - val_loss: 0.3024 - val_accuracy: 0.8928\n",
      "Epoch 444/2000\n",
      "1/1 [==============================] - 1s 943ms/step - loss: 0.2393 - accuracy: 0.9137 - val_loss: 0.3023 - val_accuracy: 0.8930\n",
      "Epoch 445/2000\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 0.2392 - accuracy: 0.9139 - val_loss: 0.3024 - val_accuracy: 0.8928\n",
      "Epoch 446/2000\n",
      "1/1 [==============================] - 1s 942ms/step - loss: 0.2392 - accuracy: 0.9139 - val_loss: 0.3023 - val_accuracy: 0.8930\n",
      "Epoch 447/2000\n",
      "1/1 [==============================] - 1s 952ms/step - loss: 0.2392 - accuracy: 0.9139 - val_loss: 0.3023 - val_accuracy: 0.8928\n",
      "Epoch 448/2000\n",
      "1/1 [==============================] - 1s 955ms/step - loss: 0.2391 - accuracy: 0.9139 - val_loss: 0.3023 - val_accuracy: 0.8930\n",
      "Epoch 449/2000\n",
      "1/1 [==============================] - 1s 943ms/step - loss: 0.2391 - accuracy: 0.9139 - val_loss: 0.3023 - val_accuracy: 0.8928\n",
      "Epoch 450/2000\n",
      "1/1 [==============================] - 1s 938ms/step - loss: 0.2391 - accuracy: 0.9139 - val_loss: 0.3023 - val_accuracy: 0.8930\n",
      "Epoch 451/2000\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 0.2390 - accuracy: 0.9140 - val_loss: 0.3023 - val_accuracy: 0.8928\n",
      "Epoch 452/2000\n",
      "1/1 [==============================] - 1s 982ms/step - loss: 0.2390 - accuracy: 0.9139 - val_loss: 0.3023 - val_accuracy: 0.8930\n",
      "Epoch 453/2000\n",
      "1/1 [==============================] - 1s 944ms/step - loss: 0.2390 - accuracy: 0.9141 - val_loss: 0.3023 - val_accuracy: 0.8928\n",
      "Epoch 454/2000\n",
      "1/1 [==============================] - 1s 940ms/step - loss: 0.2389 - accuracy: 0.9140 - val_loss: 0.3022 - val_accuracy: 0.8930\n",
      "Epoch 455/2000\n",
      "1/1 [==============================] - 1s 947ms/step - loss: 0.2389 - accuracy: 0.9141 - val_loss: 0.3023 - val_accuracy: 0.8928\n",
      "Epoch 456/2000\n",
      "1/1 [==============================] - 1s 929ms/step - loss: 0.2389 - accuracy: 0.9140 - val_loss: 0.3022 - val_accuracy: 0.8930\n",
      "Epoch 457/2000\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.2388 - accuracy: 0.9141 - val_loss: 0.3023 - val_accuracy: 0.8928\n",
      "Epoch 458/2000\n",
      "1/1 [==============================] - 1s 947ms/step - loss: 0.2388 - accuracy: 0.9140 - val_loss: 0.3022 - val_accuracy: 0.8930\n",
      "Epoch 459/2000\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 0.2388 - accuracy: 0.9142 - val_loss: 0.3023 - val_accuracy: 0.8928\n",
      "Epoch 460/2000\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 0.2387 - accuracy: 0.9140 - val_loss: 0.3022 - val_accuracy: 0.8930\n",
      "Epoch 461/2000\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.2387 - accuracy: 0.9142 - val_loss: 0.3023 - val_accuracy: 0.8928\n",
      "Epoch 462/2000\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 0.2387 - accuracy: 0.9141 - val_loss: 0.3022 - val_accuracy: 0.8930\n",
      "Epoch 463/2000\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 0.2386 - accuracy: 0.9142 - val_loss: 0.3023 - val_accuracy: 0.8928\n",
      "Epoch 464/2000\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 0.2386 - accuracy: 0.9140 - val_loss: 0.3022 - val_accuracy: 0.8930\n",
      "Epoch 465/2000\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 0.2386 - accuracy: 0.9143 - val_loss: 0.3022 - val_accuracy: 0.8930\n",
      "Epoch 466/2000\n",
      "1/1 [==============================] - 1s 938ms/step - loss: 0.2386 - accuracy: 0.9141 - val_loss: 0.3021 - val_accuracy: 0.8930\n",
      "Epoch 467/2000\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 0.2385 - accuracy: 0.9143 - val_loss: 0.3022 - val_accuracy: 0.8928\n",
      "Epoch 468/2000\n",
      "1/1 [==============================] - 1s 938ms/step - loss: 0.2385 - accuracy: 0.9141 - val_loss: 0.3021 - val_accuracy: 0.8930\n",
      "Epoch 469/2000\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 0.2385 - accuracy: 0.9144 - val_loss: 0.3022 - val_accuracy: 0.8928\n",
      "Epoch 1/2000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2417 - accuracy: 0.9128 - val_loss: 0.3029 - val_accuracy: 0.8928\n",
      "Epoch 2/2000\n",
      "1/1 [==============================] - 1s 789ms/step - loss: 0.2416 - accuracy: 0.9128 - val_loss: 0.3029 - val_accuracy: 0.8928\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 1s 930ms/step - loss: 0.2416 - accuracy: 0.9128 - val_loss: 0.3029 - val_accuracy: 0.8928\n",
      "Epoch 4/2000\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 0.2416 - accuracy: 0.9129 - val_loss: 0.3029 - val_accuracy: 0.8928\n",
      "Epoch 5/2000\n",
      "1/1 [==============================] - 1s 947ms/step - loss: 0.2416 - accuracy: 0.9129 - val_loss: 0.3029 - val_accuracy: 0.8928\n",
      "Epoch 6/2000\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 0.2416 - accuracy: 0.9129 - val_loss: 0.3028 - val_accuracy: 0.8928\n",
      "Epoch 7/2000\n",
      "1/1 [==============================] - 1s 936ms/step - loss: 0.2415 - accuracy: 0.9129 - val_loss: 0.3028 - val_accuracy: 0.8928\n",
      "Epoch 8/2000\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 0.2415 - accuracy: 0.9129 - val_loss: 0.3028 - val_accuracy: 0.8928\n",
      "Epoch 9/2000\n",
      "1/1 [==============================] - 1s 954ms/step - loss: 0.2415 - accuracy: 0.9129 - val_loss: 0.3028 - val_accuracy: 0.8928\n",
      "Epoch 10/2000\n",
      "1/1 [==============================] - 1s 944ms/step - loss: 0.2415 - accuracy: 0.9129 - val_loss: 0.3028 - val_accuracy: 0.8928\n",
      "Epoch 11/2000\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 0.2415 - accuracy: 0.9129 - val_loss: 0.3028 - val_accuracy: 0.8928\n",
      "Epoch 12/2000\n",
      "1/1 [==============================] - 1s 931ms/step - loss: 0.2414 - accuracy: 0.9130 - val_loss: 0.3028 - val_accuracy: 0.8928\n",
      "Epoch 13/2000\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 0.2414 - accuracy: 0.9130 - val_loss: 0.3028 - val_accuracy: 0.8928\n",
      "Epoch 14/2000\n",
      "1/1 [==============================] - 1s 947ms/step - loss: 0.2414 - accuracy: 0.9130 - val_loss: 0.3028 - val_accuracy: 0.8928\n",
      "Epoch 15/2000\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.2414 - accuracy: 0.9130 - val_loss: 0.3028 - val_accuracy: 0.8928\n",
      "Epoch 16/2000\n",
      "1/1 [==============================] - 1s 944ms/step - loss: 0.2414 - accuracy: 0.9130 - val_loss: 0.3028 - val_accuracy: 0.8928\n",
      "Epoch 17/2000\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 0.2413 - accuracy: 0.9130 - val_loss: 0.3028 - val_accuracy: 0.8928\n",
      "Epoch 18/2000\n",
      "1/1 [==============================] - 1s 947ms/step - loss: 0.2413 - accuracy: 0.9130 - val_loss: 0.3028 - val_accuracy: 0.8930\n",
      "Epoch 19/2000\n",
      "1/1 [==============================] - 1s 936ms/step - loss: 0.2413 - accuracy: 0.9130 - val_loss: 0.3028 - val_accuracy: 0.8930\n",
      "Epoch 20/2000\n",
      "1/1 [==============================] - 1s 970ms/step - loss: 0.2413 - accuracy: 0.9130 - val_loss: 0.3028 - val_accuracy: 0.8930\n",
      "Epoch 21/2000\n",
      "1/1 [==============================] - 1s 979ms/step - loss: 0.2413 - accuracy: 0.9130 - val_loss: 0.3028 - val_accuracy: 0.8930\n",
      "Epoch 22/2000\n",
      "1/1 [==============================] - 1s 965ms/step - loss: 0.2412 - accuracy: 0.9131 - val_loss: 0.3028 - val_accuracy: 0.8930\n",
      "Epoch 23/2000\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.2412 - accuracy: 0.9131 - val_loss: 0.3028 - val_accuracy: 0.8930\n",
      "Epoch 24/2000\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.2412 - accuracy: 0.9131 - val_loss: 0.3028 - val_accuracy: 0.8930\n",
      "Epoch 25/2000\n",
      "1/1 [==============================] - 1s 931ms/step - loss: 0.2412 - accuracy: 0.9131 - val_loss: 0.3028 - val_accuracy: 0.8930\n",
      "Epoch 26/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 934ms/step - loss: 0.2412 - accuracy: 0.9131 - val_loss: 0.3028 - val_accuracy: 0.8930\n",
      "Epoch 27/2000\n",
      "1/1 [==============================] - 1s 929ms/step - loss: 0.2411 - accuracy: 0.9131 - val_loss: 0.3028 - val_accuracy: 0.8930\n",
      "Epoch 28/2000\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 0.2411 - accuracy: 0.9131 - val_loss: 0.3028 - val_accuracy: 0.8930\n",
      "Epoch 29/2000\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.2411 - accuracy: 0.9131 - val_loss: 0.3028 - val_accuracy: 0.8930\n",
      "Epoch 30/2000\n",
      "1/1 [==============================] - 1s 966ms/step - loss: 0.2411 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8930\n",
      "Epoch 31/2000\n",
      "1/1 [==============================] - 1s 965ms/step - loss: 0.2411 - accuracy: 0.9131 - val_loss: 0.3027 - val_accuracy: 0.8930\n",
      "Epoch 32/2000\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 0.2410 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8930\n",
      "Epoch 33/2000\n",
      "1/1 [==============================] - 1s 931ms/step - loss: 0.2410 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8930\n",
      "Epoch 34/2000\n",
      "1/1 [==============================] - 1s 923ms/step - loss: 0.2410 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8930\n",
      "Epoch 35/2000\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 0.2410 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8930\n",
      "Epoch 36/2000\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 0.2410 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8930\n",
      "Epoch 37/2000\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.2410 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8930\n",
      "Epoch 38/2000\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 0.2409 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 39/2000\n",
      "1/1 [==============================] - 1s 920ms/step - loss: 0.2409 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 40/2000\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.2409 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 41/2000\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.2409 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 42/2000\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 0.2409 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 43/2000\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.2408 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 44/2000\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 0.2408 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 45/2000\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 0.2408 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 46/2000\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 0.2408 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 47/2000\n",
      "1/1 [==============================] - 1s 931ms/step - loss: 0.2408 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 48/2000\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.2407 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 49/2000\n",
      "1/1 [==============================] - 1s 931ms/step - loss: 0.2407 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 50/2000\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.2407 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 51/2000\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 0.2407 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 52/2000\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.2407 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8932\n",
      "Epoch 53/2000\n",
      "1/1 [==============================] - 1s 941ms/step - loss: 0.2406 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 54/2000\n",
      "1/1 [==============================] - 1s 924ms/step - loss: 0.2406 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8932\n",
      "Epoch 55/2000\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.2406 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8932\n",
      "Epoch 56/2000\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 0.2406 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8932\n",
      "Epoch 57/2000\n",
      "1/1 [==============================] - 1s 933ms/step - loss: 0.2406 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8932\n",
      "Epoch 58/2000\n",
      "1/1 [==============================] - 1s 953ms/step - loss: 0.2405 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8932\n",
      "Epoch 59/2000\n",
      "1/1 [==============================] - 1s 920ms/step - loss: 0.2405 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8932\n",
      "Epoch 60/2000\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 0.2405 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 61/2000\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 0.2405 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 62/2000\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.2405 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 63/2000\n",
      "1/1 [==============================] - 1s 916ms/step - loss: 0.2404 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 64/2000\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.2404 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 65/2000\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 0.2404 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 66/2000\n",
      "1/1 [==============================] - 1s 946ms/step - loss: 0.2404 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 67/2000\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 0.2404 - accuracy: 0.9134 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 68/2000\n",
      "1/1 [==============================] - 1s 966ms/step - loss: 0.2403 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8928\n",
      "Epoch 69/2000\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 0.2403 - accuracy: 0.9134 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 70/2000\n",
      "1/1 [==============================] - 1s 933ms/step - loss: 0.2403 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8928\n",
      "Epoch 71/2000\n",
      "1/1 [==============================] - 1s 924ms/step - loss: 0.2403 - accuracy: 0.9134 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 72/2000\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.2403 - accuracy: 0.9134 - val_loss: 0.3026 - val_accuracy: 0.8928\n",
      "Epoch 73/2000\n",
      "1/1 [==============================] - 1s 968ms/step - loss: 0.2403 - accuracy: 0.9134 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 74/2000\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.2402 - accuracy: 0.9133 - val_loss: 0.3025 - val_accuracy: 0.8928\n",
      "Epoch 75/2000\n",
      "1/1 [==============================] - 1s 945ms/step - loss: 0.2402 - accuracy: 0.9134 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 76/2000\n",
      "1/1 [==============================] - 1s 933ms/step - loss: 0.2402 - accuracy: 0.9134 - val_loss: 0.3025 - val_accuracy: 0.8928\n",
      "Epoch 77/2000\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 0.2402 - accuracy: 0.9134 - val_loss: 0.3025 - val_accuracy: 0.8928\n",
      "Epoch 78/2000\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 0.2402 - accuracy: 0.9134 - val_loss: 0.3025 - val_accuracy: 0.8928\n",
      "Epoch 79/2000\n",
      "1/1 [==============================] - 1s 927ms/step - loss: 0.2401 - accuracy: 0.9134 - val_loss: 0.3025 - val_accuracy: 0.8928\n",
      "Epoch 80/2000\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.2401 - accuracy: 0.9134 - val_loss: 0.3025 - val_accuracy: 0.8928\n",
      "Epoch 81/2000\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.2401 - accuracy: 0.9134 - val_loss: 0.3025 - val_accuracy: 0.8928\n",
      "Epoch 82/2000\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.2401 - accuracy: 0.9134 - val_loss: 0.3025 - val_accuracy: 0.8928\n",
      "Epoch 83/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 964ms/step - loss: 0.2401 - accuracy: 0.9135 - val_loss: 0.3025 - val_accuracy: 0.8930\n",
      "Epoch 84/2000\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.2400 - accuracy: 0.9134 - val_loss: 0.3025 - val_accuracy: 0.8928\n",
      "Epoch 85/2000\n",
      "1/1 [==============================] - 1s 921ms/step - loss: 0.2400 - accuracy: 0.9135 - val_loss: 0.3025 - val_accuracy: 0.8930\n",
      "Epoch 86/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2400 - accuracy: 0.9135 - val_loss: 0.3025 - val_accuracy: 0.8928\n",
      "Epoch 87/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2400 - accuracy: 0.9135 - val_loss: 0.3025 - val_accuracy: 0.8932\n",
      "Epoch 88/2000\n",
      "1/1 [==============================] - 1s 996ms/step - loss: 0.2400 - accuracy: 0.9135 - val_loss: 0.3025 - val_accuracy: 0.8932\n",
      "Epoch 89/2000\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 0.2399 - accuracy: 0.9135 - val_loss: 0.3025 - val_accuracy: 0.8932\n",
      "Epoch 90/2000\n",
      "1/1 [==============================] - 1s 947ms/step - loss: 0.2399 - accuracy: 0.9135 - val_loss: 0.3025 - val_accuracy: 0.8930\n",
      "Epoch 91/2000\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 0.2399 - accuracy: 0.9135 - val_loss: 0.3025 - val_accuracy: 0.8932\n",
      "Epoch 92/2000\n",
      "1/1 [==============================] - 1s 926ms/step - loss: 0.2399 - accuracy: 0.9135 - val_loss: 0.3025 - val_accuracy: 0.8932\n",
      "Epoch 93/2000\n",
      "1/1 [==============================] - 1s 947ms/step - loss: 0.2399 - accuracy: 0.9135 - val_loss: 0.3025 - val_accuracy: 0.8932\n",
      "Epoch 94/2000\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.2398 - accuracy: 0.9136 - val_loss: 0.3025 - val_accuracy: 0.8932\n",
      "Epoch 95/2000\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.2398 - accuracy: 0.9135 - val_loss: 0.3025 - val_accuracy: 0.8932\n",
      "Epoch 96/2000\n",
      "1/1 [==============================] - 1s 938ms/step - loss: 0.2398 - accuracy: 0.9136 - val_loss: 0.3025 - val_accuracy: 0.8932\n",
      "Epoch 97/2000\n",
      "1/1 [==============================] - 1s 925ms/step - loss: 0.2398 - accuracy: 0.9136 - val_loss: 0.3025 - val_accuracy: 0.8932\n",
      "Epoch 98/2000\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 0.2398 - accuracy: 0.9136 - val_loss: 0.3024 - val_accuracy: 0.8930\n",
      "Epoch 99/2000\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.2397 - accuracy: 0.9136 - val_loss: 0.3024 - val_accuracy: 0.8932\n",
      "Epoch 100/2000\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 0.2397 - accuracy: 0.9136 - val_loss: 0.3024 - val_accuracy: 0.8932\n",
      "Epoch 101/2000\n",
      "1/1 [==============================] - 1s 931ms/step - loss: 0.2397 - accuracy: 0.9136 - val_loss: 0.3024 - val_accuracy: 0.8932\n",
      "Epoch 102/2000\n",
      "1/1 [==============================] - 1s 924ms/step - loss: 0.2397 - accuracy: 0.9137 - val_loss: 0.3024 - val_accuracy: 0.8930\n",
      "Epoch 103/2000\n",
      "1/1 [==============================] - 1s 970ms/step - loss: 0.2397 - accuracy: 0.9137 - val_loss: 0.3024 - val_accuracy: 0.8932\n",
      "Epoch 104/2000\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 0.2396 - accuracy: 0.9137 - val_loss: 0.3024 - val_accuracy: 0.8930\n",
      "Epoch 105/2000\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 0.2396 - accuracy: 0.9137 - val_loss: 0.3024 - val_accuracy: 0.8932\n",
      "Epoch 106/2000\n",
      "1/1 [==============================] - 1s 936ms/step - loss: 0.2396 - accuracy: 0.9137 - val_loss: 0.3024 - val_accuracy: 0.8932\n",
      "Epoch 107/2000\n",
      "1/1 [==============================] - 1s 944ms/step - loss: 0.2396 - accuracy: 0.9137 - val_loss: 0.3024 - val_accuracy: 0.8932\n",
      "Epoch 108/2000\n",
      "1/1 [==============================] - 1s 942ms/step - loss: 0.2396 - accuracy: 0.9137 - val_loss: 0.3024 - val_accuracy: 0.8932\n",
      "Epoch 109/2000\n",
      "1/1 [==============================] - 1s 928ms/step - loss: 0.2395 - accuracy: 0.9138 - val_loss: 0.3024 - val_accuracy: 0.8932\n",
      "Epoch 110/2000\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 0.2395 - accuracy: 0.9138 - val_loss: 0.3024 - val_accuracy: 0.8932\n",
      "Epoch 111/2000\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 0.2395 - accuracy: 0.9138 - val_loss: 0.3024 - val_accuracy: 0.8932\n",
      "Epoch 112/2000\n",
      "1/1 [==============================] - 1s 947ms/step - loss: 0.2395 - accuracy: 0.9139 - val_loss: 0.3024 - val_accuracy: 0.8932\n",
      "Epoch 113/2000\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 0.2395 - accuracy: 0.9139 - val_loss: 0.3024 - val_accuracy: 0.8932\n",
      "Epoch 114/2000\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 0.2395 - accuracy: 0.9139 - val_loss: 0.3024 - val_accuracy: 0.8932\n",
      "Epoch 115/2000\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 0.2394 - accuracy: 0.9139 - val_loss: 0.3024 - val_accuracy: 0.8932\n",
      "Epoch 116/2000\n",
      "1/1 [==============================] - 1s 926ms/step - loss: 0.2394 - accuracy: 0.9139 - val_loss: 0.3024 - val_accuracy: 0.8930\n",
      "Epoch 117/2000\n",
      "1/1 [==============================] - 1s 927ms/step - loss: 0.2394 - accuracy: 0.9139 - val_loss: 0.3024 - val_accuracy: 0.8932\n",
      "Epoch 118/2000\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.2394 - accuracy: 0.9139 - val_loss: 0.3024 - val_accuracy: 0.8930\n",
      "Epoch 119/2000\n",
      "1/1 [==============================] - 1s 925ms/step - loss: 0.2394 - accuracy: 0.9139 - val_loss: 0.3024 - val_accuracy: 0.8930\n",
      "Epoch 120/2000\n",
      "1/1 [==============================] - 1s 941ms/step - loss: 0.2393 - accuracy: 0.9139 - val_loss: 0.3024 - val_accuracy: 0.8930\n",
      "Epoch 121/2000\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.2393 - accuracy: 0.9139 - val_loss: 0.3024 - val_accuracy: 0.8930\n",
      "Epoch 122/2000\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 0.2393 - accuracy: 0.9139 - val_loss: 0.3023 - val_accuracy: 0.8930\n",
      "Epoch 123/2000\n",
      "1/1 [==============================] - 1s 947ms/step - loss: 0.2393 - accuracy: 0.9140 - val_loss: 0.3023 - val_accuracy: 0.8930\n",
      "Epoch 124/2000\n",
      "1/1 [==============================] - 1s 927ms/step - loss: 0.2393 - accuracy: 0.9139 - val_loss: 0.3023 - val_accuracy: 0.8930\n",
      "Epoch 125/2000\n",
      "1/1 [==============================] - 1s 947ms/step - loss: 0.2392 - accuracy: 0.9140 - val_loss: 0.3023 - val_accuracy: 0.8930\n",
      "Epoch 126/2000\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 0.2392 - accuracy: 0.9140 - val_loss: 0.3023 - val_accuracy: 0.8930\n",
      "Epoch 127/2000\n",
      "1/1 [==============================] - 1s 885ms/step - loss: 0.2392 - accuracy: 0.9140 - val_loss: 0.3023 - val_accuracy: 0.8930\n",
      "Epoch 128/2000\n",
      "1/1 [==============================] - 1s 881ms/step - loss: 0.2392 - accuracy: 0.9140 - val_loss: 0.3023 - val_accuracy: 0.8930\n",
      "Epoch 129/2000\n",
      "1/1 [==============================] - 1s 901ms/step - loss: 0.2392 - accuracy: 0.9140 - val_loss: 0.3023 - val_accuracy: 0.8930\n",
      "Epoch 130/2000\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 0.2391 - accuracy: 0.9140 - val_loss: 0.3023 - val_accuracy: 0.8930\n",
      "Epoch 131/2000\n",
      "1/1 [==============================] - 1s 900ms/step - loss: 0.2391 - accuracy: 0.9140 - val_loss: 0.3023 - val_accuracy: 0.8930\n",
      "Epoch 132/2000\n",
      "1/1 [==============================] - 1s 915ms/step - loss: 0.2391 - accuracy: 0.9140 - val_loss: 0.3023 - val_accuracy: 0.8930\n",
      "Epoch 133/2000\n",
      "1/1 [==============================] - 1s 888ms/step - loss: 0.2391 - accuracy: 0.9140 - val_loss: 0.3023 - val_accuracy: 0.8930\n",
      "Epoch 134/2000\n",
      "1/1 [==============================] - 1s 897ms/step - loss: 0.2391 - accuracy: 0.9140 - val_loss: 0.3023 - val_accuracy: 0.8930\n",
      "Epoch 135/2000\n",
      "1/1 [==============================] - 1s 902ms/step - loss: 0.2390 - accuracy: 0.9140 - val_loss: 0.3023 - val_accuracy: 0.8930\n",
      "Epoch 136/2000\n",
      "1/1 [==============================] - 1s 909ms/step - loss: 0.2390 - accuracy: 0.9140 - val_loss: 0.3023 - val_accuracy: 0.8930\n",
      "Epoch 137/2000\n",
      "1/1 [==============================] - 1s 900ms/step - loss: 0.2390 - accuracy: 0.9140 - val_loss: 0.3023 - val_accuracy: 0.8930\n",
      "Epoch 138/2000\n",
      "1/1 [==============================] - 1s 901ms/step - loss: 0.2390 - accuracy: 0.9140 - val_loss: 0.3023 - val_accuracy: 0.8930\n",
      "Epoch 1/2000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2409 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 2/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 772ms/step - loss: 0.2409 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 1s 879ms/step - loss: 0.2409 - accuracy: 0.9131 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 4/2000\n",
      "1/1 [==============================] - 1s 885ms/step - loss: 0.2409 - accuracy: 0.9131 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 5/2000\n",
      "1/1 [==============================] - 1s 867ms/step - loss: 0.2409 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 6/2000\n",
      "1/1 [==============================] - 1s 882ms/step - loss: 0.2409 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 7/2000\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 0.2409 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 8/2000\n",
      "1/1 [==============================] - 1s 928ms/step - loss: 0.2409 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 9/2000\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.2409 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 10/2000\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 0.2409 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 11/2000\n",
      "1/1 [==============================] - 1s 901ms/step - loss: 0.2408 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 12/2000\n",
      "1/1 [==============================] - 1s 897ms/step - loss: 0.2408 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 13/2000\n",
      "1/1 [==============================] - 1s 885ms/step - loss: 0.2408 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 14/2000\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 0.2408 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 15/2000\n",
      "1/1 [==============================] - 1s 853ms/step - loss: 0.2408 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 16/2000\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 0.2408 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 17/2000\n",
      "1/1 [==============================] - 1s 851ms/step - loss: 0.2408 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 18/2000\n",
      "1/1 [==============================] - 1s 867ms/step - loss: 0.2408 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 19/2000\n",
      "1/1 [==============================] - 1s 866ms/step - loss: 0.2408 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 20/2000\n",
      "1/1 [==============================] - 1s 883ms/step - loss: 0.2408 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 21/2000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.2408 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 22/2000\n",
      "1/1 [==============================] - 1s 833ms/step - loss: 0.2408 - accuracy: 0.9132 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 23/2000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.2408 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 24/2000\n",
      "1/1 [==============================] - 1s 833ms/step - loss: 0.2408 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 25/2000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.2408 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 26/2000\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.2408 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 27/2000\n",
      "1/1 [==============================] - 1s 831ms/step - loss: 0.2407 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 28/2000\n",
      "1/1 [==============================] - 1s 832ms/step - loss: 0.2407 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 29/2000\n",
      "1/1 [==============================] - 1s 831ms/step - loss: 0.2407 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 30/2000\n",
      "1/1 [==============================] - 1s 834ms/step - loss: 0.2407 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 31/2000\n",
      "1/1 [==============================] - 1s 833ms/step - loss: 0.2407 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 32/2000\n",
      "1/1 [==============================] - 1s 833ms/step - loss: 0.2407 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 33/2000\n",
      "1/1 [==============================] - 1s 832ms/step - loss: 0.2407 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 34/2000\n",
      "1/1 [==============================] - 1s 832ms/step - loss: 0.2407 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 35/2000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.2407 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 36/2000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.2407 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 37/2000\n",
      "1/1 [==============================] - 1s 831ms/step - loss: 0.2407 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 38/2000\n",
      "1/1 [==============================] - 1s 834ms/step - loss: 0.2407 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 39/2000\n",
      "1/1 [==============================] - 1s 800ms/step - loss: 0.2407 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 40/2000\n",
      "1/1 [==============================] - 1s 813ms/step - loss: 0.2407 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 41/2000\n",
      "1/1 [==============================] - 1s 799ms/step - loss: 0.2407 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 42/2000\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 0.2406 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 43/2000\n",
      "1/1 [==============================] - 1s 814ms/step - loss: 0.2406 - accuracy: 0.9133 - val_loss: 0.3027 - val_accuracy: 0.8932\n",
      "Epoch 44/2000\n",
      "1/1 [==============================] - 1s 800ms/step - loss: 0.2406 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8932\n",
      "Epoch 45/2000\n",
      "1/1 [==============================] - 1s 801ms/step - loss: 0.2406 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8932\n",
      "Epoch 46/2000\n",
      "1/1 [==============================] - 1s 799ms/step - loss: 0.2406 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8932\n",
      "Epoch 47/2000\n",
      "1/1 [==============================] - 1s 799ms/step - loss: 0.2406 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8932\n",
      "Epoch 48/2000\n",
      "1/1 [==============================] - 1s 798ms/step - loss: 0.2406 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8932\n",
      "Epoch 49/2000\n",
      "1/1 [==============================] - 1s 815ms/step - loss: 0.2406 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8932\n",
      "Epoch 50/2000\n",
      "1/1 [==============================] - 1s 802ms/step - loss: 0.2406 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8932\n",
      "Epoch 51/2000\n",
      "1/1 [==============================] - 1s 798ms/step - loss: 0.2406 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8932\n",
      "Epoch 52/2000\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.2406 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8932\n",
      "Epoch 53/2000\n",
      "1/1 [==============================] - 1s 801ms/step - loss: 0.2406 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8932\n",
      "Epoch 54/2000\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 0.2406 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8932\n",
      "Epoch 55/2000\n",
      "1/1 [==============================] - 1s 815ms/step - loss: 0.2406 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8932\n",
      "Epoch 56/2000\n",
      "1/1 [==============================] - 1s 799ms/step - loss: 0.2406 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8932\n",
      "Epoch 57/2000\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.2405 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8932\n",
      "Epoch 58/2000\n",
      "1/1 [==============================] - 1s 824ms/step - loss: 0.2405 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8932\n",
      "Epoch 59/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 802ms/step - loss: 0.2405 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8932\n",
      "Epoch 60/2000\n",
      "1/1 [==============================] - 1s 815ms/step - loss: 0.2405 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8932\n",
      "Epoch 61/2000\n",
      "1/1 [==============================] - 1s 800ms/step - loss: 0.2405 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8932\n",
      "Epoch 62/2000\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.2405 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8932\n",
      "Epoch 63/2000\n",
      "1/1 [==============================] - 1s 832ms/step - loss: 0.2405 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 64/2000\n",
      "1/1 [==============================] - 1s 813ms/step - loss: 0.2405 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 65/2000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.2405 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 66/2000\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.2405 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 67/2000\n",
      "1/1 [==============================] - 1s 813ms/step - loss: 0.2405 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 68/2000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.2405 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 69/2000\n",
      "1/1 [==============================] - 1s 829ms/step - loss: 0.2405 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 70/2000\n",
      "1/1 [==============================] - 1s 799ms/step - loss: 0.2405 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 71/2000\n",
      "1/1 [==============================] - 1s 830ms/step - loss: 0.2405 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 72/2000\n",
      "1/1 [==============================] - 1s 814ms/step - loss: 0.2405 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 73/2000\n",
      "1/1 [==============================] - 1s 819ms/step - loss: 0.2404 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 74/2000\n",
      "1/1 [==============================] - 1s 813ms/step - loss: 0.2404 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 75/2000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.2404 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 76/2000\n",
      "1/1 [==============================] - 1s 831ms/step - loss: 0.2404 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 77/2000\n",
      "1/1 [==============================] - 1s 832ms/step - loss: 0.2404 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 78/2000\n",
      "1/1 [==============================] - 1s 819ms/step - loss: 0.2404 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 79/2000\n",
      "1/1 [==============================] - 1s 833ms/step - loss: 0.2404 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 80/2000\n",
      "1/1 [==============================] - 1s 832ms/step - loss: 0.2404 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 81/2000\n",
      "1/1 [==============================] - 1s 832ms/step - loss: 0.2404 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 82/2000\n",
      "1/1 [==============================] - 1s 879ms/step - loss: 0.2404 - accuracy: 0.9134 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 83/2000\n",
      "1/1 [==============================] - 1s 851ms/step - loss: 0.2404 - accuracy: 0.9134 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 84/2000\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 0.2404 - accuracy: 0.9134 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 85/2000\n",
      "1/1 [==============================] - 1s 841ms/step - loss: 0.2404 - accuracy: 0.9134 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 86/2000\n",
      "1/1 [==============================] - 1s 831ms/step - loss: 0.2404 - accuracy: 0.9134 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 87/2000\n",
      "1/1 [==============================] - 1s 831ms/step - loss: 0.2404 - accuracy: 0.9134 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 88/2000\n",
      "1/1 [==============================] - 1s 835ms/step - loss: 0.2403 - accuracy: 0.9134 - val_loss: 0.3026 - val_accuracy: 0.8928\n",
      "Epoch 89/2000\n",
      "1/1 [==============================] - 1s 832ms/step - loss: 0.2403 - accuracy: 0.9134 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
      "Epoch 90/2000\n",
      "1/1 [==============================] - 1s 843ms/step - loss: 0.2403 - accuracy: 0.9134 - val_loss: 0.3026 - val_accuracy: 0.8928\n",
      "Epoch 91/2000\n",
      "1/1 [==============================] - 1s 822ms/step - loss: 0.2403 - accuracy: 0.9134 - val_loss: 0.3026 - val_accuracy: 0.8928\n",
      "Epoch 92/2000\n",
      "1/1 [==============================] - 1s 833ms/step - loss: 0.2403 - accuracy: 0.9134 - val_loss: 0.3026 - val_accuracy: 0.8928\n",
      "Epoch 93/2000\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.2403 - accuracy: 0.9134 - val_loss: 0.3026 - val_accuracy: 0.8928\n",
      "Epoch 94/2000\n",
      "1/1 [==============================] - 1s 835ms/step - loss: 0.2403 - accuracy: 0.9134 - val_loss: 0.3026 - val_accuracy: 0.8928\n",
      "Epoch 95/2000\n",
      "1/1 [==============================] - 1s 833ms/step - loss: 0.2403 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8928\n",
      "Epoch 96/2000\n",
      "1/1 [==============================] - 1s 866ms/step - loss: 0.2403 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8928\n",
      "Epoch 97/2000\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 0.2403 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8928\n",
      "Epoch 98/2000\n",
      "1/1 [==============================] - 1s 848ms/step - loss: 0.2403 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8928\n",
      "Epoch 99/2000\n",
      "1/1 [==============================] - 1s 851ms/step - loss: 0.2403 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8928\n",
      "Epoch 100/2000\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 0.2403 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8928\n",
      "Epoch 101/2000\n",
      "1/1 [==============================] - 1s 866ms/step - loss: 0.2403 - accuracy: 0.9134 - val_loss: 0.3026 - val_accuracy: 0.8928\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.07,0.05,0.03,0.01]\n",
    "for lr in learning_rates:\n",
    "    model.compile(loss = keras.losses.sparse_categorical_crossentropy,\n",
    "                  optimizer = keras.optimizers.SGD(learning_rate=lr), \n",
    "                  metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, epochs=2000, validation_data=(x_val, y_val), use_multiprocessing=True, workers=4, callbacks=[callback], batch_size=55000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "110/110 [==============================] - 2s 11ms/step - loss: 0.1654 - accuracy: 0.9428 - val_loss: 0.3038 - val_accuracy: 0.8968\n",
      "Epoch 2/2000\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.1647 - accuracy: 0.9434 - val_loss: 0.3018 - val_accuracy: 0.8994\n",
      "Epoch 3/2000\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.1649 - accuracy: 0.9431 - val_loss: 0.3000 - val_accuracy: 0.8980\n",
      "Epoch 4/2000\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.1641 - accuracy: 0.9433 - val_loss: 0.3021 - val_accuracy: 0.8972\n",
      "Epoch 5/2000\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.1627 - accuracy: 0.9441 - val_loss: 0.3016 - val_accuracy: 0.8986\n",
      "Epoch 6/2000\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.1627 - accuracy: 0.9446 - val_loss: 0.3021 - val_accuracy: 0.8968\n",
      "Epoch 7/2000\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.1616 - accuracy: 0.9447 - val_loss: 0.3071 - val_accuracy: 0.8966\n",
      "Epoch 8/2000\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.1615 - accuracy: 0.9448 - val_loss: 0.3021 - val_accuracy: 0.8976\n",
      "Epoch 9/2000\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.1605 - accuracy: 0.9454 - val_loss: 0.3009 - val_accuracy: 0.8992\n",
      "Epoch 10/2000\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.1597 - accuracy: 0.9457 - val_loss: 0.3003 - val_accuracy: 0.8986\n",
      "Epoch 11/2000\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.1596 - accuracy: 0.9460 - val_loss: 0.3018 - val_accuracy: 0.8984\n",
      "Epoch 12/2000\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.1585 - accuracy: 0.9457 - val_loss: 0.3021 - val_accuracy: 0.8976\n",
      "Epoch 13/2000\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.1578 - accuracy: 0.9460 - val_loss: 0.3035 - val_accuracy: 0.8964\n",
      "Epoch 14/2000\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.1573 - accuracy: 0.9462 - val_loss: 0.3035 - val_accuracy: 0.8988\n",
      "Epoch 15/2000\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.1566 - accuracy: 0.9471 - val_loss: 0.3037 - val_accuracy: 0.8980\n",
      "Epoch 16/2000\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.1561 - accuracy: 0.9474 - val_loss: 0.3045 - val_accuracy: 0.8978\n",
      "Epoch 17/2000\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.1558 - accuracy: 0.9472 - val_loss: 0.3082 - val_accuracy: 0.8982\n",
      "Epoch 18/2000\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.1548 - accuracy: 0.9474 - val_loss: 0.3075 - val_accuracy: 0.8960\n",
      "Epoch 19/2000\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.1540 - accuracy: 0.9476 - val_loss: 0.3051 - val_accuracy: 0.8990\n",
      "Epoch 20/2000\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.1538 - accuracy: 0.9475 - val_loss: 0.3040 - val_accuracy: 0.8960\n",
      "Epoch 21/2000\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.1533 - accuracy: 0.9475 - val_loss: 0.3091 - val_accuracy: 0.8978\n",
      "Epoch 22/2000\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.1529 - accuracy: 0.9478 - val_loss: 0.3051 - val_accuracy: 0.8996\n",
      "Epoch 23/2000\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.1519 - accuracy: 0.9484 - val_loss: 0.3041 - val_accuracy: 0.8982\n",
      "Epoch 24/2000\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.1512 - accuracy: 0.9491 - val_loss: 0.3041 - val_accuracy: 0.8994\n",
      "Epoch 25/2000\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.1501 - accuracy: 0.9485 - val_loss: 0.3084 - val_accuracy: 0.8976\n",
      "Epoch 26/2000\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.1497 - accuracy: 0.9495 - val_loss: 0.3087 - val_accuracy: 0.9002\n",
      "Epoch 27/2000\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.1488 - accuracy: 0.9493 - val_loss: 0.3048 - val_accuracy: 0.8988\n",
      "Epoch 28/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.1491 - accuracy: 0.9491 - val_loss: 0.3097 - val_accuracy: 0.8996\n",
      "Epoch 29/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.1477 - accuracy: 0.9491 - val_loss: 0.3085 - val_accuracy: 0.8982\n",
      "Epoch 30/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.1472 - accuracy: 0.9504 - val_loss: 0.3111 - val_accuracy: 0.8988\n",
      "Epoch 31/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.1469 - accuracy: 0.9502 - val_loss: 0.3082 - val_accuracy: 0.8982\n",
      "Epoch 32/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.1469 - accuracy: 0.9501 - val_loss: 0.3064 - val_accuracy: 0.8978\n",
      "Epoch 33/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.1454 - accuracy: 0.9507 - val_loss: 0.3073 - val_accuracy: 0.8998\n",
      "Epoch 34/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.1447 - accuracy: 0.9512 - val_loss: 0.3090 - val_accuracy: 0.8988\n",
      "Epoch 35/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.1444 - accuracy: 0.9508 - val_loss: 0.3109 - val_accuracy: 0.8970\n",
      "Epoch 36/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.1429 - accuracy: 0.9511 - val_loss: 0.3071 - val_accuracy: 0.8984\n",
      "Epoch 37/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.1437 - accuracy: 0.9511 - val_loss: 0.3077 - val_accuracy: 0.8994\n",
      "Epoch 38/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.1428 - accuracy: 0.9504 - val_loss: 0.3092 - val_accuracy: 0.8990\n",
      "Epoch 39/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.1426 - accuracy: 0.9518 - val_loss: 0.3097 - val_accuracy: 0.8986\n",
      "Epoch 40/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1408 - accuracy: 0.9521 - val_loss: 0.3127 - val_accuracy: 0.8978\n",
      "Epoch 41/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.1411 - accuracy: 0.9523 - val_loss: 0.3111 - val_accuracy: 0.8976\n",
      "Epoch 42/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.1398 - accuracy: 0.9527 - val_loss: 0.3087 - val_accuracy: 0.8994\n",
      "Epoch 43/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1395 - accuracy: 0.9533 - val_loss: 0.3116 - val_accuracy: 0.8994\n",
      "Epoch 44/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1387 - accuracy: 0.9532 - val_loss: 0.3129 - val_accuracy: 0.8986\n",
      "Epoch 45/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.1376 - accuracy: 0.9540 - val_loss: 0.3145 - val_accuracy: 0.8982\n",
      "Epoch 46/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1377 - accuracy: 0.9537 - val_loss: 0.3127 - val_accuracy: 0.8996\n",
      "Epoch 47/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.1378 - accuracy: 0.9533 - val_loss: 0.3112 - val_accuracy: 0.8980\n",
      "Epoch 48/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.1362 - accuracy: 0.9547 - val_loss: 0.3111 - val_accuracy: 0.8982\n",
      "Epoch 49/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.1355 - accuracy: 0.9548 - val_loss: 0.3121 - val_accuracy: 0.8972\n",
      "Epoch 50/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1352 - accuracy: 0.9539 - val_loss: 0.3131 - val_accuracy: 0.8990\n",
      "Epoch 51/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1354 - accuracy: 0.9544 - val_loss: 0.3119 - val_accuracy: 0.9016\n",
      "Epoch 52/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1345 - accuracy: 0.9546 - val_loss: 0.3110 - val_accuracy: 0.8992\n",
      "Epoch 53/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1338 - accuracy: 0.9551 - val_loss: 0.3179 - val_accuracy: 0.8958\n",
      "Epoch 54/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1334 - accuracy: 0.9550 - val_loss: 0.3131 - val_accuracy: 0.8980\n",
      "Epoch 55/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1321 - accuracy: 0.9557 - val_loss: 0.3231 - val_accuracy: 0.8926\n",
      "Epoch 56/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1322 - accuracy: 0.9555 - val_loss: 0.3124 - val_accuracy: 0.8980\n",
      "Epoch 57/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1308 - accuracy: 0.9566 - val_loss: 0.3139 - val_accuracy: 0.9000\n",
      "Epoch 58/2000\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.1316 - accuracy: 0.9558 - val_loss: 0.3134 - val_accuracy: 0.8966\n",
      "Epoch 59/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1303 - accuracy: 0.9564 - val_loss: 0.3145 - val_accuracy: 0.8962\n",
      "Epoch 60/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1301 - accuracy: 0.9566 - val_loss: 0.3156 - val_accuracy: 0.8966\n",
      "Epoch 61/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1304 - accuracy: 0.9566 - val_loss: 0.3187 - val_accuracy: 0.8976\n",
      "Epoch 62/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.1292 - accuracy: 0.9567 - val_loss: 0.3195 - val_accuracy: 0.8974\n",
      "Epoch 63/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1273 - accuracy: 0.9573 - val_loss: 0.3209 - val_accuracy: 0.8954\n",
      "Epoch 64/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1270 - accuracy: 0.9573 - val_loss: 0.3300 - val_accuracy: 0.8912\n",
      "Epoch 65/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1273 - accuracy: 0.9577 - val_loss: 0.3286 - val_accuracy: 0.8956\n",
      "Epoch 66/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1273 - accuracy: 0.9575 - val_loss: 0.3233 - val_accuracy: 0.8994\n",
      "Epoch 67/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1252 - accuracy: 0.9585 - val_loss: 0.3243 - val_accuracy: 0.8966\n",
      "Epoch 68/2000\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.1248 - accuracy: 0.9581 - val_loss: 0.3252 - val_accuracy: 0.8956\n",
      "Epoch 69/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1242 - accuracy: 0.9587 - val_loss: 0.3200 - val_accuracy: 0.8966\n",
      "Epoch 70/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1237 - accuracy: 0.9589 - val_loss: 0.3210 - val_accuracy: 0.9002\n",
      "Epoch 71/2000\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.1235 - accuracy: 0.9587 - val_loss: 0.3276 - val_accuracy: 0.8942\n",
      "Epoch 72/2000\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.1229 - accuracy: 0.9595 - val_loss: 0.3235 - val_accuracy: 0.8966\n",
      "Epoch 73/2000\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.1229 - accuracy: 0.9585 - val_loss: 0.3240 - val_accuracy: 0.8976\n",
      "Epoch 74/2000\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.1205 - accuracy: 0.9600 - val_loss: 0.3208 - val_accuracy: 0.8966\n",
      "Epoch 75/2000\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.1222 - accuracy: 0.9587 - val_loss: 0.3267 - val_accuracy: 0.8974\n",
      "Epoch 76/2000\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.1201 - accuracy: 0.9605 - val_loss: 0.3200 - val_accuracy: 0.8986\n",
      "Epoch 77/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1215 - accuracy: 0.9593 - val_loss: 0.3231 - val_accuracy: 0.8942\n",
      "Epoch 78/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1195 - accuracy: 0.9602 - val_loss: 0.3309 - val_accuracy: 0.8980\n",
      "Epoch 79/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1180 - accuracy: 0.9615 - val_loss: 0.3307 - val_accuracy: 0.8992\n",
      "Epoch 80/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1191 - accuracy: 0.9607 - val_loss: 0.3259 - val_accuracy: 0.8976\n",
      "Epoch 81/2000\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.1182 - accuracy: 0.9606 - val_loss: 0.3265 - val_accuracy: 0.8974\n",
      "Epoch 82/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1182 - accuracy: 0.9600 - val_loss: 0.3228 - val_accuracy: 0.8962\n",
      "Epoch 83/2000\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.1164 - accuracy: 0.9619 - val_loss: 0.3301 - val_accuracy: 0.8978\n",
      "Epoch 84/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1162 - accuracy: 0.9614 - val_loss: 0.3287 - val_accuracy: 0.8958\n",
      "Epoch 85/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1165 - accuracy: 0.9609 - val_loss: 0.3245 - val_accuracy: 0.8978\n",
      "Epoch 86/2000\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.1145 - accuracy: 0.9621 - val_loss: 0.3289 - val_accuracy: 0.8940\n",
      "Epoch 87/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1157 - accuracy: 0.9617 - val_loss: 0.3236 - val_accuracy: 0.8998\n",
      "Epoch 88/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1152 - accuracy: 0.9620 - val_loss: 0.3304 - val_accuracy: 0.8952\n",
      "Epoch 89/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1127 - accuracy: 0.9634 - val_loss: 0.3421 - val_accuracy: 0.8948\n",
      "Epoch 90/2000\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.1123 - accuracy: 0.9627 - val_loss: 0.3399 - val_accuracy: 0.8922\n",
      "Epoch 91/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1131 - accuracy: 0.9620 - val_loss: 0.3311 - val_accuracy: 0.8956\n",
      "Epoch 92/2000\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.1155 - accuracy: 0.9611 - val_loss: 0.3434 - val_accuracy: 0.8906\n",
      "Epoch 93/2000\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.1137 - accuracy: 0.9615 - val_loss: 0.3419 - val_accuracy: 0.8972\n",
      "Epoch 94/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1114 - accuracy: 0.9631 - val_loss: 0.3314 - val_accuracy: 0.8928\n",
      "Epoch 95/2000\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.1115 - accuracy: 0.9627 - val_loss: 0.3348 - val_accuracy: 0.8960\n",
      "Epoch 96/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1111 - accuracy: 0.9634 - val_loss: 0.3393 - val_accuracy: 0.8968\n",
      "Epoch 97/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1096 - accuracy: 0.9637 - val_loss: 0.3274 - val_accuracy: 0.8988\n",
      "Epoch 98/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1081 - accuracy: 0.9651 - val_loss: 0.3317 - val_accuracy: 0.9002\n",
      "Epoch 99/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1103 - accuracy: 0.9634 - val_loss: 0.3342 - val_accuracy: 0.8950\n",
      "Epoch 100/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1116 - accuracy: 0.9631 - val_loss: 0.3709 - val_accuracy: 0.8910\n",
      "Epoch 101/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1091 - accuracy: 0.9642 - val_loss: 0.3362 - val_accuracy: 0.8948\n",
      "Epoch 102/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1051 - accuracy: 0.9657 - val_loss: 0.3316 - val_accuracy: 0.8994\n",
      "Epoch 103/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1057 - accuracy: 0.9653 - val_loss: 0.3433 - val_accuracy: 0.8948\n",
      "Epoch 104/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1081 - accuracy: 0.9642 - val_loss: 0.3323 - val_accuracy: 0.8986\n",
      "Epoch 105/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1068 - accuracy: 0.9655 - val_loss: 0.3424 - val_accuracy: 0.8942\n",
      "Epoch 106/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1059 - accuracy: 0.9651 - val_loss: 0.3395 - val_accuracy: 0.8946\n",
      "Epoch 107/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1032 - accuracy: 0.9665 - val_loss: 0.3372 - val_accuracy: 0.8984\n",
      "Epoch 108/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1036 - accuracy: 0.9667 - val_loss: 0.3333 - val_accuracy: 0.8978\n",
      "Epoch 109/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1020 - accuracy: 0.9673 - val_loss: 0.3347 - val_accuracy: 0.8982\n",
      "Epoch 110/2000\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.1036 - accuracy: 0.9662 - val_loss: 0.3432 - val_accuracy: 0.8980\n",
      "Epoch 111/2000\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.1030 - accuracy: 0.9668 - val_loss: 0.3462 - val_accuracy: 0.8924\n",
      "Epoch 112/2000\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.1025 - accuracy: 0.9667 - val_loss: 0.3426 - val_accuracy: 0.8964\n",
      "Epoch 113/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1069 - accuracy: 0.9643 - val_loss: 0.3395 - val_accuracy: 0.8966\n",
      "Epoch 114/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.1057 - accuracy: 0.9650 - val_loss: 0.3460 - val_accuracy: 0.8964\n",
      "Epoch 115/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.1016 - accuracy: 0.9673 - val_loss: 0.3449 - val_accuracy: 0.8960\n",
      "Epoch 116/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.1054 - accuracy: 0.9654 - val_loss: 0.3434 - val_accuracy: 0.8966\n",
      "Epoch 117/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1006 - accuracy: 0.9676 - val_loss: 0.3906 - val_accuracy: 0.8804\n",
      "Epoch 118/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.1011 - accuracy: 0.9665 - val_loss: 0.3457 - val_accuracy: 0.8992\n",
      "Epoch 119/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.1034 - accuracy: 0.9658 - val_loss: 0.3414 - val_accuracy: 0.8940\n",
      "Epoch 120/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.0979 - accuracy: 0.9694 - val_loss: 0.3456 - val_accuracy: 0.8956\n",
      "Epoch 121/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.0980 - accuracy: 0.9687 - val_loss: 0.3422 - val_accuracy: 0.8984\n",
      "Epoch 122/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.1006 - accuracy: 0.9670 - val_loss: 0.3459 - val_accuracy: 0.8932\n",
      "Epoch 123/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.0976 - accuracy: 0.9686 - val_loss: 0.3417 - val_accuracy: 0.8974\n",
      "Epoch 124/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.1013 - accuracy: 0.9668 - val_loss: 0.3464 - val_accuracy: 0.8968\n",
      "Epoch 125/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.0965 - accuracy: 0.9686 - val_loss: 0.3461 - val_accuracy: 0.8986\n",
      "Epoch 126/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.0954 - accuracy: 0.9696 - val_loss: 0.3903 - val_accuracy: 0.8874\n",
      "Epoch 127/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.0973 - accuracy: 0.9688 - val_loss: 0.3517 - val_accuracy: 0.8928\n",
      "Epoch 128/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.0956 - accuracy: 0.9687 - val_loss: 0.3442 - val_accuracy: 0.8970\n",
      "Epoch 129/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.0985 - accuracy: 0.9684 - val_loss: 0.3745 - val_accuracy: 0.8946\n",
      "Epoch 130/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.0939 - accuracy: 0.9697 - val_loss: 0.3512 - val_accuracy: 0.8968\n",
      "Epoch 131/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.0910 - accuracy: 0.9721 - val_loss: 0.3530 - val_accuracy: 0.8930\n",
      "Epoch 132/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.0938 - accuracy: 0.9702 - val_loss: 0.3521 - val_accuracy: 0.8984\n",
      "Epoch 133/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.0929 - accuracy: 0.9706 - val_loss: 0.3479 - val_accuracy: 0.8950\n",
      "Epoch 134/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.0932 - accuracy: 0.9697 - val_loss: 0.3592 - val_accuracy: 0.8916\n",
      "Epoch 135/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.0904 - accuracy: 0.9714 - val_loss: 0.3697 - val_accuracy: 0.8932\n",
      "Epoch 136/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.0933 - accuracy: 0.9705 - val_loss: 0.3483 - val_accuracy: 0.8960\n",
      "Epoch 137/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.0919 - accuracy: 0.9705 - val_loss: 0.3659 - val_accuracy: 0.8944\n",
      "Epoch 138/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.0892 - accuracy: 0.9720 - val_loss: 0.3632 - val_accuracy: 0.8938\n",
      "Epoch 139/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.0916 - accuracy: 0.9708 - val_loss: 0.3537 - val_accuracy: 0.8960\n",
      "Epoch 140/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.0878 - accuracy: 0.9724 - val_loss: 0.3528 - val_accuracy: 0.8968\n",
      "Epoch 141/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.0902 - accuracy: 0.9707 - val_loss: 0.3970 - val_accuracy: 0.8912\n",
      "Epoch 142/2000\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.0867 - accuracy: 0.9729 - val_loss: 0.3900 - val_accuracy: 0.8926\n",
      "Epoch 143/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.0943 - accuracy: 0.9694 - val_loss: 0.3994 - val_accuracy: 0.8908\n",
      "Epoch 144/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.0907 - accuracy: 0.9710 - val_loss: 0.3580 - val_accuracy: 0.8964\n",
      "Epoch 145/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.0847 - accuracy: 0.9734 - val_loss: 0.3653 - val_accuracy: 0.8968\n",
      "Epoch 146/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.0871 - accuracy: 0.9727 - val_loss: 0.3583 - val_accuracy: 0.8946\n",
      "Epoch 147/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.0893 - accuracy: 0.9713 - val_loss: 0.3570 - val_accuracy: 0.8964\n",
      "Epoch 148/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.0887 - accuracy: 0.9717 - val_loss: 0.3744 - val_accuracy: 0.8944\n",
      "Epoch 149/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.0896 - accuracy: 0.9710 - val_loss: 0.3622 - val_accuracy: 0.8930\n",
      "Epoch 150/2000\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.0837 - accuracy: 0.9739 - val_loss: 0.4186 - val_accuracy: 0.8826\n",
      "Epoch 151/2000\n",
      "110/110 [==============================] - 1s 13ms/step - loss: 0.0834 - accuracy: 0.9743 - val_loss: 0.3618 - val_accuracy: 0.8956\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy,\n",
    "                  optimizer = keras.optimizers.SGD(learning_rate=0.01), \n",
    "                  metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, epochs=2000, validation_data=(x_val, y_val), use_multiprocessing=True, workers=4, callbacks=[callback], batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3418 - accuracy: 0.8884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34178626537323, 0.8884000182151794]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_history = pd.DataFrame(history.history)\n",
    "model_history.plot(figsize=(10,6))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fmnist_dataset_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (Flatten)       (None, 784)               0         \n",
      "                                                                 \n",
      " hidden_layer_1 (Dense)      (None, 300)               235500    \n",
      "                                                                 \n",
      " hidden_layer_2 (Dense)      (None, 200)               60200     \n",
      "                                                                 \n",
      " hidden_layer_3 (Dense)      (None, 100)               20100     \n",
      "                                                                 \n",
      " hidden_layer_4 (Dense)      (None, 50)                5050      \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 10)                510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,360\n",
      "Trainable params: 321,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(r\"E:\\Technical\\Electro pi\\fmnist_dataset_classification_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(r\"E:\\Technical\\Electro pi\\fmnist_dataset_classification_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 3ms/step - loss: 0.3572 - accuracy: 0.8732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3571554720401764, 0.873199999332428]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_layer = model.get_layer(\"Input_layer\")\n",
    "hidden_layer_1 = model.get_layer(\"hidden_layer_1\")\n",
    "hidden_layer_2 = model.get_layer(\"hidden_layer_2\")\n",
    "output_layer = model.get_layer(\"output_layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input_layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17216794"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layer_1.get_weights()[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21915899"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layer_2.get_weights()[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8264377"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_layer.get_weights()[0].max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
